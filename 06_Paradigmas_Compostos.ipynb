{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNfJ/iRWQ0QzQztbR3mqEXo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vhrique/anne_ptbr/blob/main/06_Paradigmas_Compostos.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Paradigmas Compostos\n",
        "\n",
        "Os paradigmas compostos em redes neurais artificiais representam abordagens poderosas que integram diferentes aspectos do aprendizado simultâneo para maximizar o desempenho e a eficiência dos modelos. Entre esses paradigmas, destacam-se o multi-task learning, o multi-modal learning e o uso de joint embeddings. O multi-task learning permite que um único modelo resolva múltiplas tarefas ao mesmo tempo, aproveitando o compartilhamento de informações entre elas para melhorar a generalização e eficiência computacional. Já o multi-modal learning envolve a combinação de diferentes tipos de dados, como imagens, texto e áudio, permitindo que redes neurais integrem informações complementares de várias modalidades. Por fim, o joint embedding learning foca na criação de espaços de representação compartilhados, onde diferentes modalidades, como imagens e descrições textuais, podem ser mapeadas e comparadas diretamente, facilitando a interoperabilidade entre elas. Juntos, esses paradigmas formam a base de abordagens avançadas que ampliam o escopo e a flexibilidade das redes neurais artificiais em aplicações complexas e diversas."
      ],
      "metadata": {
        "id": "vUuWQyJ3fhC4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Multi-task Learning\n",
        "\n",
        "O multi-task learning (MTL) é um paradigma que visa resolver múltiplas tarefas simultaneamente, utilizando um único modelo. A principal motivação por trás do MTL é o compartilhamento de informação entre tarefas relacionadas, onde as representações aprendidas em uma tarefa podem beneficiar outras, levando a uma melhor generalização e redução do overfitting (Caruana, 1997). Ao compartilhar representações internas, o MTL permite que o modelo capte padrões comuns entre as tarefas, o que muitas vezes resulta em um aprendizado mais robusto e eficiente. Além disso, o MTL também proporciona eficiência computacional, pois evita a necessidade de treinar modelos separados para cada tarefa, o que pode reduzir significativamente o custo de treinamento e a complexidade do sistema. Este paradigma é amplamente utilizado em diversas áreas, como visão computacional e processamento de linguagem natural, onde tarefas inter-relacionadas podem compartilhar características comuns."
      ],
      "metadata": {
        "id": "zr6_LCzjfkXD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Formas\n",
        "\n",
        "O multi-task learning (MTL) pode ser realizado de diversas maneiras, dependendo de como as tarefas são integradas e de como as representações são compartilhadas. Uma das abordagens mais comuns é a de compartilhamento tardio de parâmetros, onde as tarefas compartilham as primeiras camadas do modelo para aprender representações gerais, e as camadas finais são específicas para cada tarefa. Outra abordagem é o compartilhamento antecipado, onde as tarefas têm redes praticamente separadas desde o início.\n",
        "\n",
        "\n",
        "Além disso, existem abordagens com redes completamente separadas que utilizam mecanismos para alinhar o aprendizado entre as tarefas, permitindo que troquem informações indiretamente, como as cross-stitch networks, ajustando as representações com base em seus respectivos contextos. Essas diferentes formas de realizar MTL são escolhidas dependendo da relação entre as tarefas e da necessidade de personalização das representações para cada uma."
      ],
      "metadata": {
        "id": "dtBEmT0sfvUp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exemplos\n",
        "\n",
        "Multi-task Learning permite o desenvolvimento de diversas aplicações. De forma simplificada, um exemplo simples pode ser considerado o multi-label classification, já que a detecção de diferentes classes são realizadas simultaneamente. Porém, costumamos utilizar o termo de MTL para tarefas mais complexas.\n",
        "\n",
        "Um grande exemplo de MTL é a detecção de objetos, visto que temos saídas nas redes neurais para classificação e regressão (bounding boxes). Também temos modelos que realizam detecção e segmentação de objetos simultâneos, caracterizando aplicações de MTL.\n",
        "\n",
        "Além de visão computacional, também é possível realizar MTL ao treinar redes para simultaneamente analisar sentimentos e classificar tópicos. Em séries temporais, podemos realizar previsão de diversas saídas simultaneamente, como previsão de demanda e preço de produtos.\n",
        "\n",
        "Aplicações mais recentes, como o desenvolvimento de veículos autônomos, envolvem não apenas realização de diversas tarefas, mas também uso de diversas modalidades de dados. Para isto, começamos também a trabalhar com Multi-modal Learning."
      ],
      "metadata": {
        "id": "dsT5WwO0f2od"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Multi-modal Learning"
      ],
      "metadata": {
        "id": "kKenHkh9fniK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Entradas Multi Modais"
      ],
      "metadata": {
        "id": "_m_UqQS1f4Qi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Perceiver"
      ],
      "metadata": {
        "id": "JDCMC9s6hvnU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Modelos para Conversão"
      ],
      "metadata": {
        "id": "QE2E4cRLf7bm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### DALL-E"
      ],
      "metadata": {
        "id": "Mp1lujVrhzK9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Joint-embedding Learning"
      ],
      "metadata": {
        "id": "AEzpWELOfqAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## CLIP"
      ],
      "metadata": {
        "id": "8UNOjeBYhsNl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Referências\n",
        "\n",
        "- Caruana, R. (1997). Multitask learning. Machine learning, 28, 41-75."
      ],
      "metadata": {
        "id": "bjYeSzfhkZQR"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ObnzhWfihtS4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}