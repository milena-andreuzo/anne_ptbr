{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP1sXPPh7OaqpPqQEhon0ma",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vhrique/anne_ptbr/blob/main/03_Visao_Computacional.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "J7OlpqTkZJbq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Arquiteturas Especializadas em Visão Computacional\n",
        "\n",
        "A visão computacional e as redes neurais evoluíram de forma interligada ao longo das últimas décadas, com avanços em uma área frequentemente impulsionando o progresso da outra. Inicialmente, o foco da visão computacional estava em algoritmos projetados manualmente para detecção de bordas, segmentação e reconhecimento de padrões. No entanto, esses métodos enfrentavam limitações ao lidar com a complexidade e variabilidade das imagens do mundo real. A introdução de redes neurais artificiais, e mais tarde de redes neurais convolucionais (CNNs), transformou a maneira como sistemas automatizados interpretam imagens, permitindo que os modelos aprendessem representações diretamente dos dados. Isso marcou o início de uma nova era, em que o aprendizado profundo começou a superar as abordagens tradicionais em várias tarefas de visão computacional, como classificação de imagens, detecção de objetos e segmentação semântica. Esse desenvolvimento conjunto continua a evoluir, com as redes neurais modernas desempenhando um papel central na visão computacional aplicada a diversos domínios, desde veículos autônomos até diagnósticos médicos."
      ],
      "metadata": {
        "id": "1-GoRR7NfU4F"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Redes Neurais Convolucionais\n",
        "\n",
        "As Redes Neurais Convolucionais (CNNs) são uma classe de redes neurais projetadas especificamente para processar dados com uma estrutura de grade, como imagens. Elas são formadas por camadas de convolução, que aplicam filtros para extrair características locais do dado, como bordas e texturas. Esses filtros são aplicados em pequenas regiões da entrada, permitindo que a CNN capture padrões espaciais e hierárquicos. Além das camadas convolucionais, as CNNs incluem camadas de pooling, que reduzem a dimensionalidade dos dados, preservando as informações mais relevantes. Graças à sua capacidade de detectar e aprender características espaciais, as CNNs são amplamente utilizadas em tarefas como reconhecimento de imagens, segmentação e detecção de objetos.\n",
        "\n",
        "<center><img src=\"https://github.com/vhrique/anne_ptbr/blob/main/figures/conv.jpg?raw=true\" width=\"500\"></center>\n",
        "\n",
        "Internamente, o processo de convolução envolve o deslizamento de um filtro (ou kernel) sobre a entrada (imagem), onde o mesmo conjunto de pesos é aplicado a diferentes regiões da imagem. A cada posição, o filtro calcula a soma ponderada dos valores dos pixels sobrepostos, resultando em uma nova matriz, chamada de mapa de características. Esse compartilhamento de pesos permite que a CNN aprenda a detectar padrões como bordas, texturas ou formas, independentemente da posição desses padrões na imagem. Isso torna a convolução altamente eficiente, pois reduz drasticamente o número de parâmetros comparado a uma rede totalmente conectada (MLP), além de explorar a estrutura local dos dados de forma eficaz."
      ],
      "metadata": {
        "id": "sS_idirHPTXP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Idéias Iniciais\n",
        "\n",
        "As redes neurais convolucionais (CNNs) têm suas raízes em pesquisas realizadas na área de biologia. Uma das primeiras inspirações foi a compreensão biológica do cortex visual de mamíferos, que revelou que neurônios na visão são organizados de maneira hierárquica, detectando bordas e padrões simples em diferentes áreas do campo visual. Na década de 1980, o pesquisador Kunihiko Fukushima desenvolveu o Neocognitron, uma rede neural hierárquica inspirada na organização visual do cérebro. O Neocognitron introduziu conceitos de convolução e pooling (ou subsampling), permitindo o reconhecimento de padrões visuais. Embora fosse uma inovação marcante, o Neocognitron não utilizava aprendizado supervisionado, sendo pré-configurado em grande parte. Foi apenas com o surgimento de técnicas de treinamento supervisionado, como o backpropagation, que as CNNs começaram a evoluir em direção ao que conhecemos hoje, culminando mais tarde na LeNet-5 de Yann LeCun, que consolidou esses avanços no reconhecimento de dígitos manuscritos."
      ],
      "metadata": {
        "id": "S2CeER9PPcUq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## LeNet-5 (1998)\n",
        "\n",
        "A LeNet-5, desenvolvida por Yann LeCun em 1998, foi uma das primeiras redes neurais convolucionais de sucesso aplicadas ao reconhecimento de dígitos manuscritos, mais especificamente no conjunto de dados MNIST. A arquitetura da LeNet-5 consistia em várias camadas de convolução e pooling, seguidas de camadas totalmente conectadas para classificação. Ela usava convoluções para extrair características visuais locais e pooling (ou subsampling) para reduzir a dimensionalidade, preservando as informações mais importantes. A rede era treinada utilizando backpropagation, o que permitiu que ela ajustasse seus pesos de forma eficiente. A LeNet-5 foi pioneira na utilização de CNNs em aplicações reais, como o reconhecimento automático de números em cheques bancários, e é considerada um marco no desenvolvimento das redes convolucionais modernas.\n",
        "\n",
        "<center><img src=\"https://github.com/vhrique/anne_ptbr/blob/main/figures/lenet5.jpg?raw=true\" width=\"800\"></br>LeNet5, desenhada com NN-SVG</center>\n",
        "\n",
        "Após isto, o progresso nas redes neurais convolucionais foi relativamente lento, em grande parte devido a limitações computacionais e à falta de grandes conjuntos de dados. Durante esse período, as CNNs eram usadas em aplicações específicas, mas não haviam atingido ampla adoção. No entanto, avanços como o uso de GPUs para acelerar o treinamento de redes profundas e o surgimento de grandes bases de dados, como o ImageNet, criaram as condições para que, em 2012, a AlexNet revolucionasse a visão computacional, demonstrando o poder das CNNs em tarefas complexas de classificação de imagens."
      ],
      "metadata": {
        "id": "n2jtE7MMPXsZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## AlexNet (2012)\n",
        "\n",
        "A AlexNet, desenvolvida por Alex Krizhevsky, Ilya Sutskever e Geoffrey Hinton em 2012, marcou um ponto de virada no campo da visão computacional ao vencer o ImageNet Large Scale Visual Recognition Challenge com uma margem significativa. Sua arquitetura foi composta por 8 camadas, sendo 5 camadas convolucionais seguidas de 3 camadas totalmente conectadas, além de funções de ativação ReLU para acelerar o treinamento e camadas de Local Response Normalization para melhorar a generalização. AlexNet introduziu o uso extensivo de GPUs para treinar redes profundas em grandes quantidades de dados, e utilizou técnicas como dropout para combater o overfitting e data augmentation para melhorar a generalização. A AlexNet demonstrou a eficácia das redes profundas e consolidou o uso de CNNs para classificação de imagens, influenciando toda uma nova geração de arquiteturas profundas.\n",
        "\n",
        "A arquitetura da AlexNet possui as seguintes camadas:\n",
        "1. Entrada: Imagem de 3 canais com tamanho 227x227\n",
        "1. Convolução 1: kernel 11x11 com 96 canais de saída, stride 4 e ativação ReLU\n",
        "1. Max-Pooling 1: 3x3 com stride 2\n",
        "1. Convolução 2: kernel 5x5 com 256 canais de saída, stride 1, padding 2 e ativação ReLU\n",
        "1. Max-Pooling 2: 3x3 com stride 2\n",
        "1. Convolução 3: kernel 3x3 com 384 canais de saída, stride 1, padding 1 e ativação ReLU\n",
        "1. Convolução 4: kernel 3x3 com 384 canais de saída, stride 1, padding 1 e ativação ReLU\n",
        "1. Convolução 5: kernel 3x3 com 256 canais de saída, stride 1, padding 1 e ativação ReLU\n",
        "1. Max-Pooling 3: 3x3 com stride 2\n",
        "1. Totalmente Conectada 1: 4096 neurônios, ativação ReLU e Dropout\n",
        "1. Totalmente Conectada 2: 4096 neurônios, ativação ReLU e Dropout\n",
        "1. Saída: 1000 neurônios, ativação Softmax\n",
        "\n",
        "<center><img src=\"https://github.com/vhrique/anne_ptbr/blob/main/figures/alexnet.png?raw=true\" width=800></br>AlexNet, desenhada com NN-SVG</center>"
      ],
      "metadata": {
        "id": "9_x1TawrPZEz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ReLU\n",
        "\n",
        "A função de ativação ReLU (Rectified Linear Unit), popularizada com a AlexNet, é uma das mais utilizadas em redes neurais modernas devido à sua simplicidade e eficácia. Sua fórmula é\n",
        "$f(x)=\\text{max}(0,x)$ , o que significa que ela transforma valores negativos em zero, enquanto mantém valores positivos inalterados. Isso introduz não-linearidade na rede, permitindo que ela aprenda padrões complexos. Comparada a funções de ativação anteriores, como sigmoid e tanh, a ReLU tem a vantagem de ser computacionalmente mais eficiente e de mitigar o problema do desvanecimento do gradiente, uma vez que seus gradientes são constantes para entradas positivas. No entanto, ReLU também pode sofrer com o problema de \"neurônios mortos\" quando muitas unidades se tornam zero, o que pode ser tratado com variantes como Leaky ReLU."
      ],
      "metadata": {
        "id": "Ejjd3wVjo57u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = np.linspace(-5, 5, 101)\n",
        "y = np.array([max(i, 0) for i in x])\n",
        "\n",
        "plt.plot(x, y)\n",
        "plt.xlabel('x')\n",
        "plt.ylabel('ReLU(x)')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "id": "UufRAcQGpOps",
        "outputId": "b477b7dc-6f4f-45cc-ba5c-927dedc1fe0b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Local Response Normalization\n",
        "\n",
        "A Local Response Normalization (LRN) é uma técnica de normalização usada em redes neurais convolucionais, introduzida pela primeira vez na AlexNet. Inspirada pela inibição lateral em neurônios biológicos, a LRN normaliza a ativação de um neurônio considerando a resposta de seus neurônios vizinhos dentro de uma pequena região. Isso ajuda a destacar ativações mais fortes e suprimir as mais fracas, promovendo uma competição entre neurônios e melhorando a generalização da rede. Embora tenha sido popular em arquiteturas antigas, como AlexNet e GoogLeNet, o LRN foi substituído por métodos mais modernos, como o Batch Normalization\n",
        "\n",
        "<center><img src=\"https://github.com/vhrique/anne_ptbr/blob/main/figures/lrnorm.jpg?raw=true\" width=300></center>"
      ],
      "metadata": {
        "id": "0ezmmYbLQDQw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Augmentation\n",
        "\n",
        "Data augmentation é uma técnica amplamente utilizada em aprendizado profundo para aumentar artificialmente o tamanho de um conjunto de dados de treinamento, aplicando transformações nos exemplos existentes. O objetivo é criar variações dos dados originais, como rotações, translações, espelhamentos, alterações de brilho, entre outras, para tornar o modelo mais robusto e generalizável. Isso é especialmente útil em tarefas como classificação de imagens, onde a diversidade dos dados pode ser limitada. Ao expor o modelo a múltiplas variações dos mesmos exemplos, o data augmentation ajuda a prevenir overfitting e a melhorar o desempenho do modelo em novos dados. Essa técnica é frequentemente usada em conjunto com outras formas de regularização, como o Dropout, para aumentar a capacidade de generalização das redes neurais.\n",
        "\n",
        "<center><img src=\"https://github.com/vhrique/anne_ptbr/blob/main/figures/augment.png?raw=true\" width=700></br>Exemplo de Data Augmentation, conforme documentação do PyTorch</center>"
      ],
      "metadata": {
        "id": "tceQCrbHo-o1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dropout\n",
        "\n",
        "O Dropout é uma técnica de regularização introduzida para reduzir o overfitting em redes neurais, particularmente em redes profundas. Ele funciona desativando aleatoriamente uma fração dos neurônios em cada camada durante o treinamento, o que força a rede a não depender excessivamente de neurônios específicos. Essa abordagem faz com que a rede aprenda representações mais robustas e generalizáveis, já que diferentes subconjuntos de neurônios são ativados em cada iteração. Durante a fase de teste, todos os neurônios são utilizados, mas os pesos são ajustados para compensar as desativações feitas no treinamento. O Dropout provou ser uma técnica eficiente em melhorar a capacidade de generalização das redes, especialmente em tarefas de classificação complexas.\n",
        "\n",
        "<center><img src=\"https://github.com/vhrique/anne_ptbr/blob/main/figures/dropout.jpg?raw=true\" width=700></center>\n",
        "\n",
        "#### Descobertas mais recentes\n",
        "\n",
        "O uso Dropout é questionado no artigo intitulado Rethinking Generalization (2017), de Zhang et al., no qual os autores argumentam que técnicas de regularização, como o Dropout, podem não ser tão eficazes quanto se pensava em redes profundas. O estudo mostrou que redes neurais profundas conseguem memorizar dados mesmo quando treinadas em conjuntos de dados completamente aleatórios. Isso sugere que, em vez de confiar exclusivamente em técnicas como Dropout para melhorar a generalização, redes neurais podem ter uma alta capacidade de generalizar mesmo sem regularização explícita. Esse achado contraria a visão tradicional de que a regularização como o Dropout seria essencial para evitar overfitting, propondo que a capacidade de generalização das redes profundas pode ser explicada por fatores além dessas técnicas, como a arquitetura ou o algoritmo de otimização."
      ],
      "metadata": {
        "id": "p-9rmWH8o802"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## VGG (2014)\n",
        "\n",
        "A VGG (Visual Geometry Group), introduzida por Simonyan e Zisserman em 2014, é uma arquitetura de rede neural convolucional projetada para classificação de imagens, que se destacou no desafio ImageNet. O principal avanço da VGG foi o uso de uma grande profundidade de camadas, com versões como VGG-16 e VGG-19, que têm 16 e 19 camadas de aprendizado, respectivamente. A arquitetura se caracteriza pelo uso de filtros convolucionais pequenos de tamanho 3x3 empilhados em sequência, juntamente com camadas de pooling para reduzir a dimensionalidade. A simplicidade dessa abordagem, aliada à profundidade, permitiu um grande aumento na capacidade de extração de características, melhorando o desempenho em várias tarefas de visão computacional. Embora a VGG tenha um alto custo computacional devido ao número elevado de parâmetros, ela teve uma influência significativa no desenvolvimento de redes neurais profundas.\n",
        "\n",
        "<center><img src=\"https://github.com/vhrique/anne_ptbr/blob/main/figures/vgg-16-90dg.png?raw=true\" width=800></center>"
      ],
      "metadata": {
        "id": "MJIt76j4PgGw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Inception/GoogleNet (2014)\n",
        "\n",
        "A Inception, introduzida por Szegedy et al. em 2014 no modelo GoogLeNet, representou uma importante inovação nas redes neurais convolucionais, projetada para melhorar tanto a eficiência computacional quanto o desempenho em tarefas de visão computacional, como o ImageNet Challenge. A principal inovação da arquitetura Inception é o módulo Inception, que aplica convoluções de diferentes tamanhos (1x1, 3x3, 5x5) e pooling em paralelo na mesma camada. Essa abordagem permite que a rede capture informações em múltiplas escalas e resoluções, melhorando a capacidade de extração de características sem aumentar significativamente o número de parâmetros.\n",
        "\n",
        "Outras inovações deste modelo foram a introdução de convoluções assimétricas, convoluções 1x1, e classificadores auxiliares. Essas inovações tornaram a GoogLeNet, com sua arquitetura Inception, uma das primeiras redes profundas a ser treinada com eficiência em grande escala, equilibrando profundidade e eficiência computacional. Essa arquitetura demonstrou que era possível criar redes neurais profundas que exploravam tanto a largura quanto a profundidade, sem incorrer no aumento exponencial de parâmetros, como acontecia com modelos anteriores. As convoluções assimétricas, em particular, foram um elemento chave para melhorar a flexibilidade e a eficiência da rede, contribuindo para sua escalabilidade e sucesso em competições de visão computacional.\n",
        "\n",
        "<center><img src=\"https://github.com/vhrique/anne_ptbr/blob/main/figures/googlenet.png?raw=true\" width=900></center>\n",
        "<center><img src=\"https://github.com/vhrique/anne_ptbr/blob/main/figures/inception.png?raw=true\"></center>\n",
        "\n"
      ],
      "metadata": {
        "id": "EqXgVi_UPiF9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Convoluções Assimétricas\n",
        "\n",
        "Além das convoluções de múltiplas escalas, um avanço significativo que surgiu em versões posteriores, como na Inception v2 e Inception v3, foi o uso de convoluções assimétricas, como as convoluções 3x1 e 1x3. Essas convoluções assimétricas foram introduzidas para melhorar ainda mais a eficiência da rede. Ao decompor uma convolução regular de 3x3 em duas operações menores, como uma convolução 3x1 (captura de características na dimensão horizontal) e uma 1x3 (captura de características na dimensão vertical), a rede pode manter o mesmo campo receptivo de uma convolução 3x3, porém com menos parâmetros e menor custo computacional. Essa técnica ajuda a rede a capturar padrões em direções específicas de forma mais eficiente, além de reduzir a quantidade de cálculos envolvidos."
      ],
      "metadata": {
        "id": "9SgfBBgiHBWe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Convoluções 1x1\n",
        "\n",
        "As convoluções 1x1 foram introduzidas para melhorar a eficiência computacional e a flexibilidade das redes neurais convolucionais, especialmente em arquiteturas como a Inception. Embora inicialmente possam parecer triviais, as convoluções 1x1 têm um papel crucial em reduzir a dimensionalidade dos dados sem perder informações relevantes. Ao aplicar um filtro 1x1, a convolução é realizada apenas sobre a profundidade (ou canais) da entrada, sem afetar a largura ou altura da imagem. Isso permite a fusão de informações de diferentes canais, o que facilita a combinação de características complexas de forma eficiente. Além disso, essa técnica reduz o número de parâmetros e operações, resultando em uma rede mais leve e rápida, o que foi fundamental para o sucesso de redes profundas como a GoogLeNet e ResNet."
      ],
      "metadata": {
        "id": "909LZcr9tOKZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Classificadores Auxiliares\n",
        "\n",
        "Além disso, a Inception introduziu os classificadores auxiliares, pequenas redes colocadas ao longo da arquitetura principal, com o objetivo de reduzir o problema do gradiente desvanecente e acelerar o treinamento da rede. Esses classificadores auxiliares atuam como uma espécie de regularizador, garantindo que camadas intermediárias da rede aprendam características úteis e não sejam prejudicadas pela dificuldade em propagar o gradiente nas camadas mais profundas."
      ],
      "metadata": {
        "id": "-SpHurkPHGiX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ResNet (2015)\n",
        "\n",
        "A ResNet (Residual Network), proposta por He et al. em 2015, revolucionou o treinamento de redes neurais profundas ao introduzir o conceito de conexões residuais (skip connections). Essas conexões permitem que o sinal original seja passado diretamente de uma camada para outra, pulando algumas camadas intermediárias. O principal benefício desse mecanismo é a solução para o problema de degradação do desempenho em redes muito profundas, onde o aumento das camadas não necessariamente melhora a performance devido à dificuldade de treinamento. Com as conexões residuais, a ResNet facilita o fluxo de gradientes durante o treinamento, tornando possível a criação de redes extremamente profundas, como a ResNet-50 e ResNet-152, sem sofrer com o gradiente desvanecente. Além disso, a ResNet foi uma das primeiras arquiteturas a fazer uso do Batch Normalization (BN), que ajudou a estabilizar o treinamento de redes profundas, melhorando a convergência. A ResNet teve um impacto profundo na pesquisa em redes neurais, estabelecendo um novo padrão para o design de arquiteturas profundas e sendo amplamente adotada em diversas tarefas de visão computacional."
      ],
      "metadata": {
        "id": "SOQ6o4TfPlsh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Conexões Residuais\n",
        "\n",
        "As conexões residuais foram a principal inovação da ResNet e representam um avanço crucial no design de redes neurais profundas. Elas introduzem um atalho que permite que o sinal original da entrada seja passado diretamente para uma camada posterior, sem passar pelas camadas intermediárias, criando o que é chamado de mapeamento de identidade. Esse conceito resolve o problema do gradiente desvanecente, que dificultava o treinamento de redes muito profundas, ao garantir que os gradientes possam fluir de forma mais eficaz para as camadas anteriores. As conexões residuais permitem que a rede aprenda diferenças residuais em vez de tentar ajustar o mapeamento completo da função, o que facilita o aprendizado. Como resultado, redes muito profundas, como as versões da ResNet com 50, 101 ou até 152 camadas, podem ser treinadas de maneira eficaz, sem degradação de desempenho, permitindo que elas capturem representações complexas dos dados.\n",
        "\n",
        "<center><img src=\"https://github.com/vhrique/anne_ptbr/blob/main/figures/resnet.png?raw=true\"></center>"
      ],
      "metadata": {
        "id": "fFKd7TCduh1R"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Batch Normalization\n",
        "\n",
        "Batch Normalization (BN), introduzido por Ioffe e Szegedy em 2015, é uma técnica que normaliza as ativações de uma camada neural para cada mini-lote durante o treinamento. O principal objetivo do Batch Normalization é mitigar o problema do deslocamento interno da covariância, que ocorre quando as distribuições das ativações mudam de forma significativa entre as camadas durante o treinamento, dificultando a convergência. Ao normalizar as ativações de cada mini-lote com base na média e na variância, o BN estabiliza e acelera o treinamento, permitindo o uso de taxas de aprendizado maiores. Além disso, o BN atua como uma forma de regularização, reduzindo a necessidade de técnicas como o Dropout, e facilita o treinamento de redes neurais mais profundas. Essa técnica foi amplamente adotada em arquiteturas modernas, como a ResNet, e se tornou um componente padrão na maioria das redes neurais convolucionais.\n",
        "\n",
        "<center><img src=\"https://github.com/vhrique/anne_ptbr/blob/main/figures/batchnorm.jpg?raw=true\" width=300></center>"
      ],
      "metadata": {
        "id": "DJrdBmNWQ1w2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Outras CNNs\n",
        "\n",
        "Nos últimos anos, várias arquiteturas de redes neurais surgiram para atender diferentes demandas de eficiência e desempenho. A MobileNet foi projetada para dispositivos móveis e embarcados, focando em eficiência computacional com o uso de convoluções separáveis em profundidade (depthwise separable convolutions), que reduzem o número de parâmetros e operações. A EfficientNet introduziu uma abordagem de escalonamento sistemático, onde largura, profundidade e resolução da rede são ajustadas de maneira balanceada para otimizar o desempenho com eficiência computacional. Já a DenseNet inovou ao utilizar conexões densas, onde cada camada recebe como entrada os mapas de características de todas as camadas anteriores, promovendo a reutilização de características e reduzindo o problema do gradiente desvanecente. Por fim, a ConvNeXt é uma arquitetura recente que moderniza as redes convolucionais ao incorporar algumas das inovações dos Transformers (como normalizações e ativação pós-camada), tornando as CNNs competitivas novamente em tarefas como visão computacional, combinando eficiência com simplicidade de design. Essas redes representam diferentes abordagens para melhorar a eficiência e a escalabilidade das redes convolucionais."
      ],
      "metadata": {
        "id": "9-vnNhXdPoTE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Aplicações\n",
        "\n",
        "As Redes Neurais Convolucionais (CNNs) são amplamente utilizadas em diversas aplicações de visão computacional, graças à sua capacidade de extrair características visuais de forma eficiente. No reconhecimento de imagens, as CNNs classificam uma imagem em categorias predefinidas, sendo amplamente utilizadas em sistemas de reconhecimento facial, diagnóstico médico e classificação de imagens em redes sociais. Na detecção de objetos, além de classificar, as CNNs também localizam múltiplos objetos dentro de uma imagem, fornecendo coordenadas para suas posições, o que é crucial para tarefas como veículos autônomos e vigilância. Já na segmentação de imagens, as CNNs não apenas identificam objetos, mas também os contornam pixel a pixel, permitindo a separação precisa de diferentes elementos dentro de uma imagem, sendo muito utilizadas em áreas como medicina (para segmentação de órgãos ou tumores) e processamento de cenas em robótica. Essas aplicações mostram a versatilidade das CNNs em resolver problemas visuais complexos."
      ],
      "metadata": {
        "id": "0Yo5-ETfg4AU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Detecção de Objetos\n",
        "\n",
        "A detecção de objetos com CNNs vai além do reconhecimento de imagens, pois não apenas identifica as categorias dos objetos, mas também localiza suas posições em uma imagem por meio de caixas delimitadoras (bounding boxes). Arquiteturas como YOLO (You Only Look Once), R-CNN e SSD (Single Shot MultiBox Detector) são amplamente utilizadas para essa tarefa. Essas redes utilizam camadas convolucionais para extrair características relevantes de uma imagem e, em seguida, classificam os objetos e preveem suas localizações simultaneamente. Geralmente, as camadas finais consistem em uma combinação de camadas totalmente conectadas ou convolucionais que geram dois tipos de saídas: uma matriz de probabilidades para classificar os objetos e outra matriz que define as posições das caixas delimitadoras, geralmente como coordenadas relativas à imagem.\n",
        "\n",
        "<center><img src=\"https://github.com/vhrique/anne_ptbr/blob/main/figures/obj_detection.jpg?raw=true\"></center>"
      ],
      "metadata": {
        "id": "vn_2dSd_Toi9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### R-CNN (2014)\n",
        "\n",
        "R-CNN (Regions with Convolutional Neural Networks) é uma arquitetura pioneira para detecção de objetos em visão computacional (Girshick et al, 2014). Ela funciona gerando propostas de regiões que possivelmente contêm objetos, usando algoritmos como busca seletiva. Cada região proposta é redimensionada e passada por uma rede neural convolucional para extração de características. Essas características são então alimentadas em um classificador, como uma SVM, para determinar a classe do objeto na região. Embora o R-CNN tenha melhorado significativamente a precisão na detecção de objetos, seu processamento é lento, pois cada região proposta precisa ser processada individualmente pela rede neural.\n",
        "\n",
        "<center><img src=\"https://github.com/vhrique/anne_ptbr/blob/main/figures/rcnn.png?raw=true\" width=700></center>\n",
        "\n",
        "A função de perda (loss function) do R-CNN combina duas partes principais: uma perda de classificação e uma perda de regressão para as caixas delimitadoras. A perda de classificação é geralmente uma entropia cruzada que avalia a precisão da previsão da classe do objeto em cada região proposta. Já a perda de regressão avalia a precisão na predição das coordenadas da caixa delimitadora, geralmente usando um erro quadrático ou L1/L2 loss. Essas duas perdas são combinadas para ajustar a rede, garantindo que ela não apenas classifique corretamente os objetos, mas também localize-os de maneira precisa."
      ],
      "metadata": {
        "id": "Wg9E3I5Dg-9c"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Segmentação de Imagens\n",
        "\n",
        "A segmentação de imagens com CNNs é uma técnica mais avançada do que a detecção de objetos, pois, em vez de apenas localizar e classificar objetos, ela envolve atribuir uma classe a cada pixel da imagem, separando diferentes objetos ou regiões de interesse com precisão. Existem dois tipos principais de segmentação: segmentação semântica, que classifica cada pixel em uma categoria (por exemplo, carro, pedestre, estrada), e segmentação de instâncias, que diferencia objetos individuais da mesma classe (por exemplo, identificar vários carros em uma imagem separadamente).\n",
        "\n",
        "<center><img src=\"https://github.com/vhrique/anne_ptbr/blob/main/figures/image_segmentation.png?raw=true\" width=500></center>\n",
        "\n",
        "A arquitetura para segmentação de imagens com CNNs geralmente segue um formato de encoder-decoder. O encoder é responsável por extrair características da imagem, utilizando camadas convolucionais e operações de pooling para reduzir a resolução espacial, semelhante ao que acontece em arquiteturas de reconhecimento de imagens ou detecção de objetos. O decoder é usado para restaurar a resolução original da imagem, aplicando camadas de upsampling (como transposed convolutions ou interpolações) para gerar uma saída na mesma resolução da entrada."
      ],
      "metadata": {
        "id": "o3sukCdVhDHT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Outras Aplicações\n",
        "\n",
        "Embora as CNNs sejam amplamente conhecidas por suas aplicações em visão computacional, elas também têm sido adaptadas para lidar com séries temporais e outros tipos de dados não visuais. Em séries temporais, as CNNs podem capturar padrões locais ao longo do tempo, assim como capturam padrões espaciais em imagens, aplicando convoluções para detectar tendências, sazonalidades ou eventos relevantes em sequências temporais. Por exemplo, CNNs são usadas em previsões financeiras, onde conseguem identificar padrões em dados históricos de preços, ou em análise de sinais biomédicos, como ECGs, para detectar anomalias de saúde. Além disso, CNNs têm sido aplicadas a dados textuais para tarefas de classificação de texto e análise de sentimentos, onde as convoluções identificam sequências de palavras ou frases relevantes. Ao lidar com dados sequenciais, as CNNs competem com RNNs e Transformers, mostrando que são versáteis e eficazes em diversos tipos de dados, além de imagens."
      ],
      "metadata": {
        "id": "0_sISC3_hG9A"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exercícios\n",
        "\n",
        "1. Verifique o exemplo da aula 3 para visão computacional.\n",
        "2. Porque a EfficientNet-Lite0 foi menos eficiente que a LeNet5?\n",
        "3. Como podemos melhorar a resultado da EfficientNet-Lite0? Implemente esta solução."
      ],
      "metadata": {
        "id": "vCJSzsBOTNIw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Referências\n",
        "\n",
        "- Fukushima, K. (1980). Neocognitron: A self-organizing neural network model for a mechanism of pattern recognition unaffected by shift in position. Biological cybernetics, 36(4), 193-202.\n",
        "- LeCun, Y., Bottou, L., Bengio, Y., & Haffner, P. (1998). Gradient-based learning applied to document recognition. Proceedings of the IEEE, 86(11), 2278-2324.\n",
        "- LeNail, (2019). NN-SVG: Publication-Ready Neural Network Architecture Schematics. Journal of Open Source Software, 4(33), 747, https://doi.org/10.21105/joss.00747\n",
        "- Krizhevsky, A., Sutskever, I., & Hinton, G. E. (2012). Imagenet classification with deep convolutional neural networks. Advances in neural information processing systems, 25.\n",
        "- Nair, V., & Hinton, G. E. (2010). Rectified linear units improve restricted boltzmann machines. In Proceedings of the 27th international conference on machine learning (ICML-10) (pp. 807-814).\n",
        "- Zhang, C., Bengio, S., Hardt, M., Recht, B., & Vinyals, O. (2021). Understanding deep learning (still) requires rethinking generalization. Communications of the ACM, 64(3), 107-115.\n",
        "- Zhang, C., Bengio, S., Hardt, M., Recht, B., & Vinyals, O. (2021). Understanding deep learning (still) requires rethinking generalization. Communications of the ACM, 64(3), 107-115.\n",
        "- Simonyan, K., & Zisserman, A. (2014). Very deep convolutional networks for large-scale image recognition. arXiv preprint arXiv:1409.1556.\n",
        "- Szegedy, C., Liu, W., Jia, Y., Sermanet, P., Reed, S., Anguelov, D., ... & Rabinovich, A. (2015). Going deeper with convolutions. In Proceedings of the IEEE conference on computer vision and pattern recognition (pp. 1-9).\n",
        "- He, K., Zhang, X., Ren, S., & Sun, J. (2016). Deep residual learning for image recognition. In Proceedings of the IEEE conference on computer vision and pattern recognition (pp. 770-778).\n",
        "- Ioffe, S. (2015). Batch normalization: Accelerating deep network training by reducing internal covariate shift. arXiv preprint arXiv:1502.03167.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "fpwSyDT9TPKA"
      }
    }
  ]
}