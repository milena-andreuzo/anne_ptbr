{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNV5CjCY0DVuDJwpYCxyYz1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vhrique/anne_ptbr/blob/main/04b_Transformers.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Mecanismos de Atenção e Transformers\n",
        "\n",
        "Transformers surgiram com o artigo Attention Is All You Need (Vaswani et al., 2017), que propôs uma ruptura em relação às arquiteturas sequenciais tradicionais, como RNNs e LSTMs. A ideia central é o mecanismo de atenção, que permite ao modelo relacionar diretamente diferentes partes de uma sequência sem depender de processamento passo a passo, favorecendo paralelismo e eficiência em grandes volumes de dados. Desde então, transformers tornaram-se a base de modelos de linguagem de larga escala (como BERT, GPT e T5), além de expandirem para outras áreas como visão computacional (Vision Transformers), bioinformática e previsão de séries temporais. Sua flexibilidade em lidar com dados sequenciais e estruturados os consolidou como a arquitetura dominante em aprendizado profundo atual."
      ],
      "metadata": {
        "id": "TQh_toRcitZj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Mecanismos de Atenção (2014)\n",
        "\n",
        "Para superar as limitações das RNNs tradicionais, foi introduzido o mecanismo de atenção, que permite que a rede \"preste atenção\" em diferentes partes da sequência, independentemente da posição (Bahdanau et al., 2014). O mecanismo de atenção atua como um complemento ao processo recorrente, permitindo que a rede atribua pesos diferentes a diferentes elementos da entrada e capture informações relevantes, mesmo que estejam distantes na sequência. Isso melhora significativamente a capacidade das RNNs de lidar com dependências de longo alcance. Aplicações como a atenção em tradução automática demonstraram que esse mecanismo é eficaz para focar em palavras específicas de uma sentença ao traduzir, superando parte das limitações das RNNs puras.\n",
        "\n",
        "<center><img src=\"https://github.com/vhrique/anne_ptbr/blob/main/figures/bahdanau.JPG?raw=true\"></center>\n",
        "\n",
        "Na arquitetura de Bahdanu (2014) mostrada acima, vemos um modelo Sequência a Sequência (_Sequence to Sequence_ - Seq2seq), onde temos um codificador e um decodificador. No exemplo, o codificador é uma RNN bidirecional que extrai características $h_i$ para cada token $x_i$ na sequência de entrada $\\textbf{x}$ com comprimento $T$. O decodificador é uma RNN que calcula a saída $y_i$ de forma iterativa, passo-a-passo, utilizando o estado interno $s_i$, a saída anterior $y_{i-1}$ e um contexto $c_i$, enquanto o estado interno $s_i$ é uma função da saída anterior $y_{i-1}$, o estado anterior $s_{i-1}$ e o contexto $c_i$. Este contexto $c_i$ é uma média ponderada de todas as características $h_i$ calculadas pelo codificador, em função de pesos de atenção $a_i$. Cada um dos pesos de atenção $a_i$ é calculado como uma função das características $h_i$ e o estado interno do decodificador $s_{i-1}$. Neste caso, todas as funções são redes neurais aprendidas com os próprios dados."
      ],
      "metadata": {
        "id": "Y3bdrIbEQjcR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Transformers (2017)\n",
        "\n",
        "Com base no sucesso dos mecanismos de atenção, os Transformers, introduzidos em 2017 por Vasvani et al., levaram essa ideia ao próximo nível ao eliminar completamente a necessidade de recorrência. Os Transformers utilizam atenção auto-regressiva para processar toda a sequência de dados de uma vez, permitindo que a rede identifique dependências de curto e longo prazo de maneira eficiente, sem os problemas de gradientes desvanecentes. Isso também permite uma alta paralelização do processamento, acelerando consideravelmente o treinamento em grandes volumes de dados. Desde sua introdução, os Transformers se tornaram a arquitetura dominante em tarefas de processamento de linguagem natural e outras áreas, como visão computacional, devido à sua flexibilidade e eficiência.\n",
        "\n",
        "A arquitetura do Transformer é baseada inteiramente em mecanismos de atenção, sem o uso de recorrência ou convolução. Ela consiste em dois blocos principais: um encoder e um decoder, ambos compostos de múltiplas camadas. Cada camada do encoder é formada por duas subcamadas principais: atenção auto-regressiva (self-attention), que permite que a rede atribua pesos a diferentes partes da sequência de entrada, e uma camada feed-forward que processa as características extraídas. O decoder segue uma estrutura similar, com a adição de uma subcamada de atenção cruzada que se conecta ao encoder, além de sua própria atenção auto-regressiva. Uma característica chave do Transformer é o uso de embeddings posicionais, que adicionam informações sobre a ordem dos elementos da sequência, algo que as RNNs capturam de forma nativa, mas que o Transformer precisa compensar. Essa estrutura permite que o Transformer processe sequências inteiras de forma paralelizada, tornando-o extremamente eficiente em tarefas como tradução automática, processamento de linguagem natural e até visão computacional.\n",
        "\n",
        "<center><img src=\"https://github.com/vhrique/anne_ptbr/blob/main/figures/transformer.png?raw=true\" width=300></center>\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "i8GK6vH0p3JR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Self-Attention\n",
        "\n",
        "A self-attention (atenção auto-regressiva) é um mecanismo usado para permitir que modelos atribuam pesos diferentes a diferentes partes de uma sequência de entrada, dependendo da relevância contextual entre elas. Em vez de processar uma sequência de dados de forma sequencial, a self-attention permite que o modelo \"preste atenção\" em todas as posições da sequência simultaneamente, calculando a importância de cada elemento em relação aos outros. Isso é feito ao gerar três vetores para cada token da sequência: query (consulta), key (chave) e value (valor). O modelo calcula as similaridades entre as queries e keys, produzindo uma pontuação de atenção, que é usada para ponderar os valores correspondentes. Com o self-attention, o modelo pode identificar relações importantes em toda a sequência, de maneira eficiente e paralelizada.\n",
        "\n",
        "<center><img src=\"https://github.com/vhrique/anne_ptbr/blob/main/figures/self-attention.png?raw=true\" width=600></center>"
      ],
      "metadata": {
        "id": "0C8yaOm2p7Ii"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Layer Normalization\n",
        "\n",
        "Os Transformers lidam com sequências de comprimento variável, como frases ou parágrafos, onde cada token depende de sua posição na sequência. O BatchNorm, que normaliza as ativações com base em todo o lote, pode interferir nessas dependências temporais. Por outro lado, o LayerNorm normaliza cada amostra de forma independente, sem depender de outras amostras no lote, preservando assim as dependências temporais e contextuais dentro das sequências.\n",
        "\n",
        "<center><img src=\"https://github.com/vhrique/anne_ptbr/blob/main/figures/layernorm.jpg?raw=true\" width=300></center>\n",
        "\n",
        "A Layer Normalization (LayerNorm) foi introduzida em 2016, em um artigo intitulado \"Layer Normalization\" por Jimmy Lei Ba, Jamie Ryan Kiros e Geoffrey Hinton. A técnica foi desenvolvida para normalizar as ativações das camadas de redes neurais recorrentes de forma independente em cada amostra, ao invés de calcular as estatísticas em lotes de dados como no Batch Normalization."
      ],
      "metadata": {
        "id": "8y63YF5vp9B0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Arquiteturas Discriminativas e Generativas\n",
        "\n",
        "O Transformer revolucionou o processamento de linguagem natural (NLP) ao substituir arquiteturas sequenciais, como RNNs e LSTMs, por um mecanismo de atenção auto-regressiva que processa todo o contexto de uma sequência simultaneamente e de maneira paralela. Isso não apenas eliminou as limitações de capturar dependências de longo prazo, mas também permitiu uma paralelização eficiente do treinamento, acelerando significativamente o processamento em grandes volumes de dados. Modelos baseados no Transformer, como BERT e GPT, redefiniram o estado da arte em tarefas de NLP, como tradução, resposta a perguntas e geração de texto, graças à sua capacidade de capturar contextos complexos de maneira bidirecional ou autoregressiva."
      ],
      "metadata": {
        "id": "k5Alyw8qQsy7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Arquiteturas Discriminativas e BERT (2018)\n",
        "\n",
        "O BERT (Bidirectional Encoder Representations from Transformers) é uma aplicação avançada da arquitetura Transformer, especificamente do **encoder** do Transformer, desenvolvido pela Google em 2018. Enquanto o Transformer completo possui um componente de encoder e decoder para tarefas como tradução, o BERT utiliza apenas o encoder, focando em capturar o contexto bidirecional de uma palavra em uma sequência de texto. Isso significa que BERT analisa cada palavra levando em consideração as palavras à esquerda e à direita, ao contrário de modelos unidirecionais que só olham em uma direção. O uso dessa arquitetura Transformer bidirecional permite ao BERT obter representações de texto altamente contextualizadas, tornando-o extremamente eficaz para tarefas de processamento de linguagem natural, como perguntas e respostas, reconhecimento de entidades e análise de sentimento.\n",
        "\n",
        "<center><img src=\"https://github.com/vhrique/anne_ptbr/blob/main/figures/bert.jpg?raw=true\" width=700></center>\n",
        "\n",
        "BERT é treinado usando duas tarefas principais: máscara de palavras (Masked Language Modeling), onde o modelo tenta prever palavras escondidas em uma sentença, e previsão de sentenças adjacentes (Next Sentence Prediction), onde ele prevê se uma frase segue logicamente a outra. Essa abordagem permite ao BERT capturar nuances complexas de significado e relações contextuais profundas, o que o torna altamente eficaz em tarefas como classificação de texto, resposta a perguntas e tradução automática."
      ],
      "metadata": {
        "id": "gN09mMCzqghJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Arquiteturas Generativas e GPT (2018-...)\n",
        "\n",
        "O GPT-1 (Generative Pre-trained Transformer) foi o primeiro modelo da série GPT, introduzido pela OpenAI em 2018. Ele se baseia na arquitetura do **decoder** do Transformer, utilizando uma abordagem unidirecional para processar texto, ou seja, cada token é gerado com base apenas nos tokens anteriores da sequência. Ao contrário do BERT, que é bidirecional, o GPT-1 foca na tarefa de modelagem de linguagem em que o modelo é pré-treinado para prever a próxima palavra em uma sequência de texto. O GPT-1 foi pré-treinado em uma grande quantidade de dados não supervisionados, sendo posteriormente ajustado para tarefas específicas de NLP, como tradução e classificação, com um processo simples de fine-tuning. Sua principal inovação foi a demonstração de que o pré-treinamento de modelos de linguagem em grandes volumes de dados seguido por ajuste fino pode produzir excelentes resultados em diversas tarefas de linguagem natural.\n",
        "\n",
        "<center><img src=\"https://github.com/vhrique/anne_ptbr/blob/main/figures/gpt.JPG?raw=true\" width=700></center>\n",
        "\n",
        "Com o lançamento de versões mais avançadas, como GPT-3 e GPT-4, o modelo se destacou pela sua capacidade de realizar uma ampla gama de tarefas, como tradução, resposta a perguntas, escrita criativa e geração de código, sem precisar de grandes quantidades de dados anotados. O uso de zero-shot e few-shot learning com GPT permitiu ao modelo generalizar para novas tarefas apenas com descrições mínimas ou alguns exemplos, transformando a maneira como abordamos o processamento de linguagem natural e outras aplicações de IA."
      ],
      "metadata": {
        "id": "7PR8EFZrqlpj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# O Transformer como um _Mixer_ de Informações\n",
        "\n",
        "O encoder do transformer pode ser entendido como um mecanismo de mistura de informações entre elementos de uma sequência ou conjunto, seja ela composta por palavras em um texto, patches de uma imagem, sinais em séries temporais ou mesmo conjuntos de atributos. Isso ocorre porque cada camada do encoder aplica self-attention, permitindo que cada entrada seja contextualizada em relação a todas as outras, redistribuindo a informação de forma dinâmica e dependente da tarefa. Esse processo resulta em representações ricas e globais, que não ficam limitadas a relações locais, como em convoluções ou recorrências. Por isso, o encoder é amplamente reutilizado como um bloco genérico de extração de representações.\n",
        "\n",
        "<center><img src=\"https://github.com/vhrique/anne_ptbr/blob/main/figures/attention_fix.jpg?raw=true\" width=800></center>"
      ],
      "metadata": {
        "id": "5N2Lj-96r8Xi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Lidando com em Escalabilidade em Transformers\n",
        "\n",
        "Os Transformers, apesar de sua eficiência em capturar dependências globais, enfrentam desafios de escalabilidade, especialmente com dados de alta dimensão, como imagens e vídeos, devido ao alto custo computacional da auto-atenção, que cresce quadraticamente com o tamanho da entrada. Uma inovação é o Flash Attention, que otimiza o cálculo da auto-atenção ao reduzir o uso de memória e acelerar o processamento em GPUs. Esse tipo de avanço está tornando os Transformers mais eficientes e escaláveis para uma gama maior de aplicações e volumes de dados. Alguns exemplos seguem abaixo.\n",
        "\n",
        "### Linformer\n",
        "\n",
        "O Linformer é uma variante dos Transformers que foi proposta para reduzir a complexidade computacional do cálculo de auto-atenção, que tradicionalmente cresce de forma quadrática com o número de tokens de entrada. A inovação do Linformer é a ideia de aproximar as matrizes de atenção de uma forma que elas tenham uma dimensão fixa, independentemente do comprimento da sequência de entrada. Isso é feito por meio de uma projeção linear das sequências, o que reduz o custo computacional da auto-atenção para complexidade linear. Essa abordagem torna o Linformer significativamente mais eficiente, especialmente em tarefas que envolvem sequências longas, como processamento de linguagem natural e visão computacional, sem comprometer a precisão dos modelos. O Linformer é particularmente útil para ambientes com restrições de recursos e para treinar modelos em grandes conjuntos de dados com alta eficiência.\n",
        "\n",
        "### Reformer\n",
        "\n",
        "O Reformer é uma arquitetura otimizada de Transformers, proposta para lidar com os desafios de escalabilidade e eficiência no processamento de grandes sequências. O Reformer introduz duas inovações principais para reduzir a complexidade computacional e o uso de memória. A primeira é o uso de Locality-Sensitive Hashing (LSH) na camada de auto-atenção, que aproxima a atenção ao comparar tokens similares de forma eficiente, reduzindo a complexidade da auto-atenção de quadrática para subquadrática. A segunda inovação é o uso de codificação reversível, o que elimina a necessidade de armazenar os estados intermediários de cada camada durante o treinamento, reduzindo significativamente o uso de memória. Essas melhorias tornam o Reformer capaz de processar sequências muito longas, como textos extensos ou vídeos, de forma mais escalável e eficiente, enquanto mantém a precisão dos Transformers tradicionais.\n",
        "\n",
        "### Big Bird\n",
        "\n",
        "O Big Bird é uma variante dos Transformers projetada para lidar com sequências extremamente longas, como documentos completos ou genomas, onde o cálculo tradicional de auto-atenção seria inviável devido ao alto custo computacional. Em vez de usar a atenção plena, o Big Bird introduz uma atenção esparsa que combina três tipos de atenção: local, global e aleatória. A atenção local captura relações próximas entre tokens, a atenção global foca em tokens importantes em posições fixas, e a atenção aleatória cria conexões entre tokens distantes de forma esparsa. Essa combinação reduz a complexidade da auto-atenção de quadrática para linear, permitindo o processamento eficiente de sequências muito maiores sem sacrificar o desempenho. O Big Bird se mostrou eficaz em várias tarefas de processamento de linguagem natural, como classificação de documentos, modelagem de linguagem, e até tarefas em bioinformática, demonstrando sua versatilidade e eficiência para grandes volumes de dados.\n",
        "\n",
        "<center><img src=\"https://github.com/vhrique/anne_ptbr/blob/main/figures/big-bird.png?raw=true\" width=500></center>\n",
        "\n",
        "### Flash Attention\n",
        "\n",
        "Flash Attention é uma técnica recente desenvolvida para otimizar o cálculo do mecanismo de auto-atenção em Transformers, reduzindo o uso de memória e acelerando o processamento. Tradicionalmente, o cálculo da auto-atenção tem um custo computacional quadrático em relação ao número de tokens de entrada, o que torna o processamento de sequências longas caro e ineficiente. O Flash Attention resolve esse problema ao realizar os cálculos de atenção de forma mais eficiente, armazenando somas parciais diretamente na memória e realizando as operações de forma fragmentada. Isso não só reduz o uso de memória como também melhora o desempenho em hardware como GPUs, permitindo que os Transformers processem sequências maiores com menos recursos computacionais. Essa técnica é especialmente útil em modelos grandes e para aplicações em larga escala, como processamento de linguagem natural e visão computacional."
      ],
      "metadata": {
        "id": "LlRXpy1pRhO7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Considerações Finais\n",
        "\n",
        "Na aula, abordamos arquiteturas fundamentais de redes neurais para processamento de sequencias: RNNs, projetadas para lidar com dados sequenciais, como séries temporais e texto, capturando dependências temporais; e Transformers, que revolucionaram o processamento de linguagem natural e, mais recentemente, a visão computacional, ao usar mecanismos de atenção auto-regressiva para capturar relações globais de forma eficiente e paralelizada. Cada uma dessas arquiteturas tem aplicações específicas e vantagens únicas, sendo marcos importantes no desenvolvimento da inteligência artificial.\n",
        "\n",
        "## RNN vs Transformer\n",
        "\n",
        "As RNNs e os Transformers são ambos usados para processar dados sequenciais, mas diferem fundamentalmente em seu funcionamento. As RNNs processam a sequência de dados de forma sequencial, etapa por etapa, o que limita a eficiência e dificulta a captura de dependências de longo prazo devido ao problema do gradiente desvanecente. Já os Transformers utilizam o mecanismo de self-attention, permitindo que o modelo capture dependências em qualquer posição da sequência de forma paralelizada e mais eficiente, superando as limitações das RNNs. Como resultado, os Transformers têm se tornado o padrão em muitas tarefas de processamento de linguagem natural e visão computacional, substituindo as RNNs em diversas aplicações.\n",
        "\n",
        "## CNN vs ViT\n",
        "\n",
        "As CNNs (Redes Neurais Convolucionais) e os Vision Transformers (ViT) são ambas arquiteturas utilizadas para visão computacional, mas diferem na forma como processam imagens. As CNNs utilizam convoluções locais, aplicando filtros para detectar padrões como bordas e texturas em pequenas regiões da imagem, com forte viés indutivo sobre a estrutura espacial. Já o ViT trata a imagem como uma sequência de patches (pequenos blocos), utilizando o mecanismo de self-attention para capturar relações globais e locais de forma mais flexível. As CNNs são mais eficientes em conjuntos de dados menores, mas o ViT se destaca em grandes volumes de dados, onde pode superar as CNNs em termos de desempenho, graças à sua capacidade de modelar dependências globais de maneira eficiente.\n",
        "\n",
        "## MLP vs Transformer\n",
        "\n",
        "As MLPs (Multilayer Perceptrons) e os Transformers são ambas redes neurais, mas têm diferenças fundamentais em como processam dados. O MLP é uma arquitetura mais simples, composta por camadas totalmente conectadas que tratam cada entrada de forma independente, sem considerar a estrutura dos dados. Isso limita sua capacidade de capturar relações complexas ou estruturais entre os elementos dos dados, como sequências temporais ou imagens. Em contraste, os Transformers utilizam o mecanismo de self-attention, permitindo que o modelo capture dependências globais entre diferentes partes de uma sequência, como palavras em um texto ou patches em uma imagem, de forma mais eficiente. Enquanto os MLPs são eficientes em tarefas simples e estruturadas, os Transformers se destacam em tarefas que exigem capturar relações contextuais complexas, como processamento de linguagem natural e visão computacional.\n",
        "\n",
        "## Próxima Aula\n",
        "\n",
        "Na próxima aula, trataremos sobre paradigmas avançados de redes neurais artificiais, como aprendizagem auto-supervisionada, contrastive learning e meta-learning."
      ],
      "metadata": {
        "id": "h7m_6tpES5xC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exercícios\n",
        "\n",
        "1. Verifique os exemplos da aula 4 para série temporal e processamento de linguagem natural\n",
        "2. Responda as seguintes perguntas:\n",
        "  1. Porque a LSTM foi mais eficiente que a MLP?\n",
        "  2. Qual a grande desvantagem de Transformers?\n",
        "3. Altere a LSTM por uma GRU no exemplo 4.a. Qual foi o resultado?"
      ],
      "metadata": {
        "id": "vCJSzsBOTNIw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Referências\n",
        "\n",
        "- Bahdanau, D. (2014). Neural machine translation by jointly learning to align and translate. arXiv preprint arXiv:1409.0473.\n",
        "- Vaswani, A. (2017). Attention is all you need. Advances in Neural Information Processing Systems.\n",
        "- Ba, J. L. (2016). Layer normalization. arXiv preprint arXiv:1607.06450.\n",
        "- Devlin, J. (2018). Bert: Pre-training of deep bidirectional transformers for language understanding. arXiv preprint arXiv:1810.04805.\n",
        "- Radford, A. (2018). Improving language understanding by generative pre-training.\n",
        "- Radford, A., Wu, J., Child, R., Luan, D., Amodei, D., & Sutskever, I. (2019). Language models are unsupervised multitask learners. OpenAI blog, 1(8), 9.\n",
        "- Brown, T. B. (2020). Language models are few-shot learners. arXiv preprint arXiv:2005.14165.\n",
        "- Achiam, J., Adler, S., Agarwal, S., Ahmad, L., Akkaya, I., Aleman, F. L., ... & McGrew, B. (2023). Gpt-4 technical report. arXiv preprint arXiv:2303.08774.\n",
        "- Wang, S., Li, B. Z., Khabsa, M., Fang, H., & Ma, H. (2020). Linformer: Self-attention with linear complexity. arXiv preprint arXiv:2006.04768.\n",
        "- Kitaev, N., Kaiser, Ł., & Levskaya, A. (2020). Reformer: The efficient transformer. arXiv preprint arXiv:2001.04451.\n",
        "- Zaheer, M., Guruganesh, G., Dubey, K. A., Ainslie, J., Alberti, C., Ontanon, S., ... & Ahmed, A. (2020). Big bird: Transformers for longer sequences. Advances in neural information processing systems, 33, 17283-17297.\n",
        "- Dao, T., Fu, D., Ermon, S., Rudra, A., & Ré, C. (2022). Flashattention: Fast and memory-efficient exact attention with io-awareness. Advances in Neural Information Processing Systems, 35, 16344-16359.\n",
        "\n"
      ],
      "metadata": {
        "id": "fpwSyDT9TPKA"
      }
    }
  ]
}