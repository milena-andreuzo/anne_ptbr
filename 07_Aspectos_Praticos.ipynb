{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNaMOq2lW2CKlHkE+yA//ei",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vhrique/anne_ptbr/blob/main/07_Aspectos_Praticos.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Introdução a Aspectos Práticos\n",
        "\n",
        "Aspectos práticos em redes neurais envolvem a aplicação eficiente e adaptável dessas arquiteturas em diferentes cenários. Um dos principais desafios está nos paradigmas de aprendizagem com dados limitados, onde técnicas como few-shot learning e zero-shot learning permitem que redes neurais generalizem bem com poucas ou nenhuma amostra de treinamento. Além disso, a redução de modelos, através de métodos como pruning e quantização, é essencial para otimizar o desempenho e a viabilidade de implantação em dispositivos com recursos limitados. Outro ponto crucial é a domain adaptation, que visa ajustar modelos treinados em um domínio para que se adaptem a novos contextos sem precisar de grandes volumes de dados rotulados. Por fim, dicas para o treinamento eficiente de redes neurais Esta aula trata sobre estes assuntos, incluindo uma seção final com dicas para criação de redes neurais artificiais.\n",
        "\n"
      ],
      "metadata": {
        "id": "VkRa-OD96pWr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Paradigmas de Aprendizagem com Dados Limitados\n",
        "\n",
        "Os paradigmas de aprendizagem com dados limitados são fundamentais para lidar com a escassez de dados rotulados. O transfer learning permite que modelos pré-treinados em grandes conjuntos de dados sejam adaptados a novas tarefas com menos dados, enquanto o few-shot learning utiliza poucas amostras para treinar modelos que conseguem generalizar bem. Já o zero-shot learning possibilita que modelos reconheçam classes inéditas sem amostras diretas, baseando-se em descrições ou relações semânticas. Essas abordagens otimizam o uso de dados reduzidos, acelerando o aprendizado e melhorando a adaptação dos modelos.\n",
        "\n",
        "## Transfer Learning\n",
        "\n",
        "Transfer learning é uma técnica poderosa em redes neurais que permite reutilizar o conhecimento adquirido por um modelo pré-treinado em uma tarefa de origem para resolver uma tarefa diferente, geralmente com menos dados disponíveis. Ao invés de treinar um modelo do zero, o transfer learning aproveita as camadas iniciais de um modelo, que capturam características genéricas dos dados, e ajusta as camadas finais para a nova tarefa. Isso resulta em uma aceleração do processo de treinamento e, frequentemente, em uma melhoria no desempenho, especialmente em cenários onde o volume de dados rotulados é limitado. É amplamente utilizado em áreas como visão computacional e processamento de linguagem natural, onde redes pré-treinadas em grandes bases de dados podem ser adaptadas para aplicações mais específicas e especializadas.\n",
        "\n",
        "O transfer learning teve aplicações pioneiras em diferentes áreas, começando com aprendizado por reforço nos anos 90, onde Lorien Pratt introduziu a ideia de transferência entre tarefas relacionadas. No processamento de linguagem natural, o word2vec (2013) trouxe uma abordagem importante ao pré-treinar representações de palavras que podiam ser adaptadas a diferentes tarefas linguísticas. Já em visão computacional, o AlexNet (2012) marcou um grande avanço ao ser pré-treinado no ImageNet e posteriormente refinado para resolver problemas específicos com menos dados, consolidando o uso de transfer learning em redes neurais profundas.\n",
        "\n",
        "\n",
        "## Few-shot Learning\n",
        "\n",
        "Few-shot learning é uma abordagem de aprendizado que permite que modelos generalizem bem a partir de um número extremamente reduzido de amostras de treinamento (Li et al., 2016). Em vez de depender de grandes volumes de dados, como na aprendizagem tradicional, o few-shot learning utiliza técnicas avançadas, como redes siamesas e prototípicas, para aprender a diferença entre classes a partir de poucos exemplos. O objetivo é ensinar o modelo a identificar padrões e características gerais que possam ser aplicados a novas amostras com pouca informação. Essa técnica tem sido especialmente útil em áreas como reconhecimento de imagens, onde rotular grandes quantidades de dados é caro ou inviável.\n",
        "\n",
        "## Zero-shot Learning\n",
        "\n",
        "O primeiro trabalho marcante sobre zero-shot learning foi \"Zero-Shot Learning with Semantic Output Codes\" (Palatucci et al.) publicado em 2009. Neste estudo, os autores apresentaram uma abordagem para reconhecimento de objetos em categorias para as quais o modelo não tinha exemplos diretos durante o treinamento. O método utiliza descrições semânticas das classes conhecidas para fazer inferências sobre novas classes, permitindo que o modelo reconheça objetos sem ter visto exemplos específicos dessas classes anteriormente. Esse trabalho introduziu o conceito de zero-shot learning ao explorar como características semânticas podem ser utilizadas para generalizar além das classes rotuladas, marcando o início de uma nova linha de pesquisa em aprendizagem de máquina."
      ],
      "metadata": {
        "id": "nZQxyrrFLq01"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Redução de Modelos\n",
        "\n",
        "A redução de modelos, ou model compression, é uma técnica utilizada para otimizar redes neurais, diminuindo seu tamanho e complexidade sem sacrificar significativamente o desempenho. Métodos como pruning, quantização e knowledge distillation são comumente empregados para reduzir a quantidade de parâmetros e operações no modelo, tornando-o mais eficiente em termos de armazenamento e tempo de inferência. Pruning remove conexões ou neurônios irrelevantes, enquanto a quantização reduz a precisão dos números utilizados, como passando de 32 bits para 8 bits, para diminuir o uso de memória. Já o knowledge distillation envolve treinar um modelo menor (aluno) a partir das previsões de um modelo maior (professor), transferindo seu conhecimento de maneira compacta. Essas técnicas são particularmente valiosas para a implementação de redes neurais em dispositivos com recursos limitados, como celulares ou sistemas embarcados.\n",
        "\n",
        "## Prunning\n",
        "\n",
        "O conceito de pruning em redes neurais foi introduzido pela primeira vez no paper \"Optimal Brain Damage\" (LeCun et al., 1990). Neste trabalho seminal, os autores propuseram uma técnica para reduzir a complexidade de redes neurais removendo pesos que tivessem pouca influência sobre o desempenho geral do modelo. A abordagem se baseava na ideia de eliminar conexões irrelevantes ou com pequena contribuição para a função de perda, visando simplificar a rede sem comprometer significativamente sua precisão. Esse trabalho abriu caminho para uma série de técnicas de pruning que se tornaram fundamentais para a compressão de modelos e o desenvolvimento de redes neurais mais eficientes.\n",
        "\n",
        "## Quantization\n",
        "\n",
        "A quantization é uma técnica essencial na computação de deep learning que busca reduzir a precisão numérica dos parâmetros de uma rede neural, como pesos e ativações, para representações de menor bit-depth, como 8-bit, sem comprometer significativamente o desempenho do modelo. Ela permite a execução mais eficiente em termos de memória e poder de processamento, sendo amplamente aplicada em dispositivos de borda e inferência em tempo real. Um paper seminal nessa área é \"Quantizing Deep Convolutional Networks for Efficient Inference: A Whitepaper\" (Jacob et al., 2018), que explora a quantização de redes profundas com foco em eficiência computacional.\n",
        "\n",
        "## Model Distillation\n",
        "\n",
        "Model distillation é uma técnica em aprendizado de máquina utilizada para transferir o conhecimento de um modelo grande e complexo, geralmente chamado de teacher model, para um modelo menor e mais eficiente, conhecido como student model. A ideia central é que o modelo grande pode capturar padrões mais sutis nos dados, e o modelo menor aprende a replicar esse comportamento ao ser treinado para imitar as saídas ou as distribuições de probabilidade produzidas pelo modelo maior. Isso é útil para reduzir a complexidade computacional e o tamanho dos modelos, tornando-os mais adequados para execução em dispositivos com recursos limitados, sem perder muita precisão. O trabalho seminal na área é \"Distilling the Knowledge in a Neural Network\" (Hinton et al., 2015), que introduz a técnica e explora como o student model pode alcançar desempenho comparável ao teacher model com uma arquitetura mais compacta."
      ],
      "metadata": {
        "id": "ZrgrjUHHEScM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Generalização de Domínio\n",
        "\n",
        "A generalização de domínio é uma área de pesquisa em aprendizado de máquina que busca desenvolver modelos capazes de generalizar bem para novos domínios, ou seja, dados que possuem distribuições diferentes das usadas no treinamento. Em muitos casos, os modelos de aprendizado de máquina podem superestimar sua capacidade de adaptação, apresentando desempenho ruim quando expostos a dados com variações não vistas anteriormente, como mudanças de iluminação, ângulo ou contexto em tarefas de visão computacional. A generalização de domínio visa mitigar esse problema, criando métodos que garantam robustez em ambientes diversos sem a necessidade de grandes volumes de dados rotulados em cada novo domínio.\n",
        "\n",
        "## Supervised Domain Adaptation\n",
        "\n",
        "Supervised domain adaptation é uma técnica em aprendizado de máquina que visa adaptar um modelo treinado em um domínio de origem (source domain) para funcionar bem em um domínio de destino (target domain), onde ambos os domínios possuem rótulos disponíveis. A principal diferença entre o domínio de origem e o de destino está nas distribuições dos dados, que podem variar significativamente. A abordagem supervisionada permite que o modelo use rótulos no domínio de destino para ajustar suas previsões e melhorar seu desempenho ao longo do tempo. O objetivo é minimizar a discrepância entre os domínios, fazendo com que o modelo aproveite melhor as informações do domínio de origem para ser mais eficaz no domínio de destino.\n",
        "\n",
        "## Unsupervised Domain Adaptation\n",
        "\n",
        "Unsupervised domain adaptation é uma técnica em aprendizado de máquina que visa adaptar um modelo treinado em um domínio de origem (source domain) para realizar boas previsões em um domínio de destino (target domain) sem a necessidade de rótulos no domínio de destino. A principal dificuldade está na diferença nas distribuições entre os dois domínios, o que pode causar uma queda significativa no desempenho do modelo se ele não for adaptado. Para superar essa discrepância, técnicas de unsupervised domain adaptation buscam alinhar as representações dos dados dos dois domínios de maneira a torná-las mais semelhantes, usando abordagens como o aprendizado adversarial, mapeamento de características invariantes ou regularização baseada em discrepâncias.\n",
        "\n",
        "## Test-time Adaptation\n",
        "\n",
        "Test-time adaptation é uma abordagem emergente em aprendizado de máquina que busca adaptar o modelo durante o tempo de teste, ao invés de depender apenas do treinamento prévio. A ideia é ajustar o modelo de forma contínua enquanto ele processa novos dados, especialmente em cenários onde as condições de distribuição dos dados mudam dinamicamente, como em sistemas autônomos ou aplicações de visão computacional em tempo real. O objetivo é permitir que o modelo ajuste suas representações e parâmetros com base nos dados de entrada no momento da inferência, mesmo sem rótulos disponíveis, utilizando técnicas como auto-supervisão ou entropia mínima para otimizar sua performance em tempo de execução. Um trabalho relevante nessa área é \"Tent: Fully Test-Time Adaptation by Entropy Minimization\" (Wang et al., 2020), que propõe um método de adaptação utilizando a minimização da entropia das previsões durante o teste para melhorar a robustez do modelo em novos ambientes."
      ],
      "metadata": {
        "id": "D8dELunQEVmv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Receita para Treinar Redes Neurais Artificiais\n",
        "\n",
        "Andrej Karpathy, em seu famoso post \"A Recipe for Training Neural Networks\", compartilha uma abordagem prática e eficiente para treinar redes neurais artificiais. Ele destaca que o sucesso no treinamento depende de uma combinação cuidadosa de boas práticas. A receita inclui começar com arquiteturas simples e testar rapidamente a performance do modelo antes de complicá-lo. Ele recomenda ajustar o aprendizado de maneira incremental, focando em entender o comportamento do modelo com overfitting e underfitting. Entre as dicas valiosas, Karpathy enfatiza o uso de visualizações para compreender o comportamento da rede, a importância de usar lotes de dados adequados, e a prática de sempre monitorar as métricas de performance."
      ],
      "metadata": {
        "id": "GgAdKog4B87Y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Análise Exploratória de Dados\n",
        "\n",
        "A análise exploratória de dados (EDA) é uma etapa fundamental no desenvolvimento de modelos de machine learning, conforme destacado no tópico \"Become One with the Data\", de Andrej Karpathy. O objetivo da EDA é obter uma compreensão profunda dos dados antes de construir qualquer modelo. Isso inclui a visualização de distribuições, detecção de outliers, análise de correlações e identificação de padrões ou anomalias que possam afetar o desempenho do modelo. Karpathy enfatiza que passar tempo com os dados, analisando suas características e peculiaridades, é crucial para tomar decisões informadas sobre pré-processamento, engenharia de features e seleção de algoritmos. Em resumo, a EDA permite que o pesquisador se familiarize com o comportamento dos dados, maximizando as chances de sucesso do modelo final."
      ],
      "metadata": {
        "id": "ppGKdJ5TCAdg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Criar uma Arquitetura Inicial\n",
        "\n",
        "Ao criar uma arquitetura inicial para redes neurais, é importante adotar uma abordagem estruturada que facilite o processo de treinamento e depuração. O uso de boas práticas, desde a escolha de padrões arquiteturais até a normalização dos dados, ajuda a garantir que o modelo aprenda de maneira eficaz. Além disso, a realização de testes em conjuntos de dados reduzidos pode fornecer uma visão clara de como o modelo está se comportando e ajudar na identificação precoce de falhas.\n",
        "\n",
        "\n",
        "- Iniciar com padrões (arquiteturas e otimizadores): Utilize arquiteturas consagradas como MLPs ou CNNs, e otimizadores como Adam ou SGD, que são confiáveis e amplamente utilizados.\n",
        "\n",
        "- Normalizar dados: Assegure-se de que os dados estejam normalizados, garantindo que as variáveis de entrada estejam em escalas semelhantes, facilitando o aprendizado.\n",
        "\n",
        "- Uso de conjuntos reduzidos (para overfit): Teste o modelo em um conjunto de dados pequeno para verificar se ele consegue overfit. Isso ajuda a garantir que o modelo e a função de perda estão funcionando corretamente.\n",
        "\n",
        "- Diagnóstico de falhas no treino: Se o modelo não consegue overfit em um conjunto pequeno, pode haver problemas na arquitetura, nos hiperparâmetros ou na implementação, e isso requer uma investigação mais detalhada."
      ],
      "metadata": {
        "id": "ocvDm1INCDFR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Avaliar Modelo\n",
        "\n",
        "A avaliação de modelo é uma etapa crucial no desenvolvimento de redes neurais, pois permite verificar se o modelo está aprendendo adequadamente e se generaliza bem para novos dados. Além de medir a acurácia ou outras métricas de desempenho, a análise detalhada dos erros cometidos pelo modelo é fundamental para identificar áreas de melhoria e ajustar os hiperparâmetros ou a arquitetura. As curvas de aprendizagem também são ferramentas valiosas, pois mostram como o desempenho do modelo evolui ao longo do tempo durante o treinamento e ajudam a detectar problemas como overfitting ou underfitting.\n",
        "\n",
        "Aqui estão alguns itens importantes para a análise de erros e curvas de aprendizagem:\n",
        "\n",
        "- Identificar erros sistemáticos: Verifique se o modelo está cometendo erros semelhantes em determinados tipos de exemplos. Isso pode indicar a necessidade de melhorar a representação dos dados ou ajustar o pré-processamento.\n",
        "\n",
        "- Comparar performance de treino e validação: Analisar a diferença entre as curvas de erro no conjunto de treino e no de validação ajuda a identificar overfitting (quando o erro de validação é muito maior que o de treino) ou underfitting (quando ambos os erros são altos).\n",
        "\n",
        "- Monitorar a convergência: Acompanhe as curvas de aprendizado para garantir que o modelo está convergindo corretamente. Caso a perda não esteja diminuindo, pode ser necessário ajustar a taxa de aprendizado ou rever a arquitetura.\n",
        "\n",
        "- Ajustar com base nos erros: Use os insights dos erros para ajustar a arquitetura, os hiperparâmetros ou até o pré-processamento dos dados, sempre com o objetivo de melhorar o desempenho do modelo."
      ],
      "metadata": {
        "id": "uZRsep0o-PPv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Overfit\n",
        "\n",
        "Garantir que o modelo consiga overfit no conjunto de treino é uma etapa crítica para verificar se ele tem a capacidade de aprender os padrões, mesmo que de forma exagerada. Para isso, algumas abordagens podem ser seguidas, como simplificar o problema e ajustar os parâmetros da rede. Caso o modelo não consiga overfit, pode haver problemas na arquitetura ou na implementação.\n",
        "\n",
        "Aqui estão alguns pontos importantes a serem observados:\n",
        "\n",
        "- Reduzir regularização: Desative técnicas como dropout e weight decay, que impedem o overfitting, para facilitar a memorização.\n",
        "\n",
        "- Aumentar a capacidade do modelo: Adicione mais neurônios ou camadas à rede para garantir que ela tenha capacidade suficiente para aprender.\n",
        "\n",
        "- Ajustar a taxa de aprendizado: Verifique se a taxa de aprendizado está adequada, já que uma taxa muito alta pode impedir o modelo de aprender corretamente.\n",
        "\n",
        "- Testar a função de perda: Certifique-se de que a função de perda está bem configurada e que o modelo consegue otimizar seu valor no conjunto de treino."
      ],
      "metadata": {
        "id": "_YoQKxNqCGhl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Regularização\n",
        "\n",
        "A regularização é fundamental para evitar que o modelo overfit aos dados de treino, permitindo uma melhor generalização para dados novos. Existem diversas técnicas que podem ser aplicadas em diferentes etapas do treinamento para melhorar o desempenho do modelo. A seguir, uma ordem recomendada de abordagens para regularização:\n",
        "\n",
        "- Adicionar mais dados: A maneira mais eficaz de melhorar a generalização é aumentar o tamanho do conjunto de dados com mais exemplos reais, sempre que possível.\n",
        "\n",
        "- Data augmentation: Se não for possível coletar mais dados, utilize técnicas de aumento de dados, como rotações, escalas ou distorções, para criar variações nos exemplos de treino.\n",
        "\n",
        "- Normalização de representações: Use batch normalization ou layer normalization para estabilizar o aprendizado, acelerar a convergência e melhorar a generalização do modelo.\n",
        "\n",
        "- Redução do batch size: Diminuir o tamanho do batch pode introduzir mais ruído no treinamento, ajudando o modelo a escapar de mínimos locais e generalizar melhor.\n",
        "\n",
        "- Dropout e regularização de parâmetros: Aplique dropout ou técnicas de regularização como weight decay para evitar que o modelo dependa muito de combinações específicas de parâmetros.\n",
        "\n",
        "- Label smoothing: Use label smoothing para suavizar as probabilidades de saída, reduzindo a confiança excessiva do modelo nas previsões e melhorando a generalização.\n",
        "\n",
        "- Early stopping: Monitore o erro de validação e pare o treinamento antes que o modelo comece a overfit, quando o erro de validação aumenta enquanto o erro de treino diminui.\n",
        "\n",
        "- Modificação de tamanho de modelo: Se o overfitting persistir, considere reduzir o número de neurônios ou camadas da rede para evitar que o modelo tenha capacidade excessiva de memorização."
      ],
      "metadata": {
        "id": "ltO_THRZCJnM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Refinar\n",
        "\n",
        "O refinamento de redes neurais é um processo contínuo de ajuste fino que busca otimizar o desempenho do modelo após a fase inicial de treinamento. Isso envolve ajustes precisos dos hiperparâmetros e o uso de técnicas avançadas para melhorar a estabilidade e a convergência do modelo. Refinar redes neurais é essencial para alcançar um bom equilíbrio entre desempenho e eficiência, garantindo que o modelo atinja seu potencial máximo em termos de precisão e generalização.\n",
        "\n",
        "Aqui estão algumas abordagens para o refinamento:\n",
        "\n",
        "- Ajuste de hiperparâmetros: Experimente diferentes valores para hiperparâmetros importantes, como taxa de aprendizado, tamanho do batch, número de camadas e unidades por camada, para encontrar a combinação que melhora o desempenho do modelo.\n",
        "\n",
        "- Schedule de learning rate: Use um learning rate schedule que diminua a taxa de aprendizado ao longo do tempo. Técnicas como step decay ou cosine annealing ajudam a estabilizar o treinamento e encontrar um mínimo mais preciso.\n",
        "\n",
        "- Exponential Moving Average (EMA): Mantenha uma média exponencial dos pesos do modelo durante o treinamento. Essa técnica ajuda a suavizar as atualizações e pode melhorar a robustez do modelo, especialmente quando usado em conjunto com learning rate schedules."
      ],
      "metadata": {
        "id": "oQOE9w2bNqCL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Referências\n",
        "\n",
        "- Pratt, L. Y., Mostow, J., & Kamm, C. A. (1991, July). Direct transfer of learned information among neural networks. In Proceedings of the ninth National conference on Artificial intelligence-Volume 2 (pp. 584-589).\n",
        "- Mikolov, T. (2013). Efficient estimation of word representations in vector space. arXiv preprint arXiv:1301.3781.\n",
        "- Fei-Fei, L., Fergus, R., & Perona, P. (2006). One-shot learning of object categories. IEEE transactions on pattern analysis and machine intelligence, 28(4), 594-611.\n",
        "- Palatucci, M., Pomerleau, D., Hinton, G. E., & Mitchell, T. M. (2009). Zero-shot learning with semantic output codes. Advances in neural information processing systems, 22.\n",
        "- LeCun, Y., Denker, J., & Solla, S. (1989). Optimal brain damage. Advances in neural information processing systems, 2.\n",
        "- Krishnamoorthi, R. (2018). Quantizing deep convolutional networks for efficient inference: A whitepaper. arXiv preprint arXiv:1806.08342.\n",
        "- Hinton, G. (2015). Distilling the Knowledge in a Neural Network. arXiv preprint arXiv:1503.02531.\n",
        "\n",
        "- Wang, D., Shelhamer, E., Liu, S., Olshausen, B., & Darrell, T. (2020). Tent: Fully test-time adaptation by entropy minimization. arXiv preprint arXiv:2006.10726."
      ],
      "metadata": {
        "id": "yGqSqEREmDfY"
      }
    }
  ]
}