{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMOccJPTYIR4JW1pdKkuFYx",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vhrique/anne_ptbr/blob/main/03_Arquiteturas_Discriminativas.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "J7OlpqTkZJbq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Redes Neurais Convolucionais\n",
        "\n",
        "As Redes Neurais Convolucionais (CNNs) são uma classe de redes neurais projetadas especificamente para processar dados com uma estrutura de grade, como imagens. Elas são formadas por camadas de convolução, que aplicam filtros para extrair características locais do dado, como bordas e texturas. Esses filtros são aplicados em pequenas regiões da entrada, permitindo que a CNN capture padrões espaciais e hierárquicos. Além das camadas convolucionais, as CNNs incluem camadas de pooling, que reduzem a dimensionalidade dos dados, preservando as informações mais relevantes. Graças à sua capacidade de detectar e aprender características espaciais, as CNNs são amplamente utilizadas em tarefas como reconhecimento de imagens, segmentação e detecção de objetos.\n",
        "\n",
        "<center><img src=\"https://github.com/vhrique/anne_ptbr/blob/main/figures/conv.jpg?raw=true\" width=\"\"></center>\n",
        "\n",
        "Internamente, o processo de convolução envolve o deslizamento de um filtro (ou kernel) sobre a entrada (imagem), onde o mesmo conjunto de pesos é aplicado a diferentes regiões da imagem. A cada posição, o filtro calcula a soma ponderada dos valores dos pixels sobrepostos, resultando em uma nova matriz, chamada de mapa de características. Esse compartilhamento de pesos permite que a CNN aprenda a detectar padrões como bordas, texturas ou formas, independentemente da posição desses padrões na imagem. Isso torna a convolução altamente eficiente, pois reduz drasticamente o número de parâmetros comparado a uma rede totalmente conectada (MLP), além de explorar a estrutura local dos dados de forma eficaz."
      ],
      "metadata": {
        "id": "sS_idirHPTXP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Idéias Iniciais\n",
        "\n",
        "As redes neurais convolucionais (CNNs) têm suas raízes em pesquisas realizadas na área de biologia. Uma das primeiras inspirações foi a compreensão biológica do cortex visual de mamíferos, que revelou que neurônios na visão são organizados de maneira hierárquica, detectando bordas e padrões simples em diferentes áreas do campo visual. Na década de 1980, o pesquisador Kunihiko Fukushima desenvolveu o Neocognitron, uma rede neural hierárquica inspirada na organização visual do cérebro. O Neocognitron introduziu conceitos de convolução e pooling (ou subsampling), permitindo o reconhecimento de padrões visuais. Embora fosse uma inovação marcante, o Neocognitron não utilizava aprendizado supervisionado, sendo pré-configurado em grande parte. Foi apenas com o surgimento de técnicas de treinamento supervisionado, como o backpropagation, que as CNNs começaram a evoluir em direção ao que conhecemos hoje, culminando mais tarde na LeNet-5 de Yann LeCun, que consolidou esses avanços no reconhecimento de dígitos manuscritos."
      ],
      "metadata": {
        "id": "S2CeER9PPcUq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## LeNet-5 (1998)\n",
        "\n",
        "A LeNet-5, desenvolvida por Yann LeCun em 1998, foi uma das primeiras redes neurais convolucionais de sucesso aplicadas ao reconhecimento de dígitos manuscritos, mais especificamente no conjunto de dados MNIST. A arquitetura da LeNet-5 consistia em várias camadas de convolução e pooling, seguidas de camadas totalmente conectadas para classificação. Ela usava convoluções para extrair características visuais locais e pooling (ou subsampling) para reduzir a dimensionalidade, preservando as informações mais importantes. A rede era treinada utilizando backpropagation, o que permitiu que ela ajustasse seus pesos de forma eficiente. A LeNet-5 foi pioneira na utilização de CNNs em aplicações reais, como o reconhecimento automático de números em cheques bancários, e é considerada um marco no desenvolvimento das redes convolucionais modernas.\n",
        "\n",
        "<center><img src=\"https://github.com/vhrique/anne_ptbr/blob/main/figures/lenet5.jpg?raw=true\" width=\"500\"></center>"
      ],
      "metadata": {
        "id": "n2jtE7MMPXsZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## AlexNet (2012)"
      ],
      "metadata": {
        "id": "9_x1TawrPZEz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## VGG (2014)"
      ],
      "metadata": {
        "id": "MJIt76j4PgGw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Inception/GoogleNet (2014)"
      ],
      "metadata": {
        "id": "EqXgVi_UPiF9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ResNet (2015)"
      ],
      "metadata": {
        "id": "SOQ6o4TfPlsh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Outras CNNs\n",
        "\n",
        "- MobileNet\n",
        "- EficientNet\n",
        "- DenseNet\n",
        "- ConvNext"
      ],
      "metadata": {
        "id": "9-vnNhXdPoTE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Aplicações\n",
        "\n",
        "### Reconhecimento de Imagens\n",
        "\n",
        "### Detecção de Objetos\n",
        "\n",
        "### Segmentação de Imagens"
      ],
      "metadata": {
        "id": "vn_2dSd_Toi9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Redes Neurais Recorrentes"
      ],
      "metadata": {
        "id": "QA3IsL6YQNUY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## RNNs Clássicas (1980s)"
      ],
      "metadata": {
        "id": "PdvBrbOOQQe0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## LSTM (1997)"
      ],
      "metadata": {
        "id": "yu8g4hKfQV2C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## GRU (2014)"
      ],
      "metadata": {
        "id": "_LkQgCM1Qa0Y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Transformers"
      ],
      "metadata": {
        "id": "h4gH4FSHQhtZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Mecanismos de Atenção (2014)"
      ],
      "metadata": {
        "id": "Y3bdrIbEQjcR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Transformer (2017)"
      ],
      "metadata": {
        "id": "OlReclPXQnbI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Avanços em Processamento de Linguagem Natural\n",
        "\n",
        "### BERT (2018)\n",
        "\n",
        "### GPT (2018-2023)"
      ],
      "metadata": {
        "id": "k5Alyw8qQsy7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Avanços em Visão Computacional\n",
        "\n",
        "### Vision Transformer (2020)\n",
        "\n",
        "### Swin Transformer (2021)"
      ],
      "metadata": {
        "id": "WwubgE61Qv-I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Avanços em Escalabilidade\n",
        "\n",
        "### Perceiver e Perceiver IO (2021)\n",
        "\n",
        "## Flash Attention\n",
        "\n",
        "### Linformer\n",
        "\n",
        "### Reformer\n",
        "\n",
        "### Big Bird"
      ],
      "metadata": {
        "id": "LlRXpy1pRhO7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Considerações Finais\n",
        "\n",
        "## Diferenças nas Arquiteturas\n",
        "\n",
        "### RNN vs Transformer\n",
        "\n",
        "### CNN vs ViT\n",
        "\n",
        "### MLP vs Transformer\n",
        "\n",
        "## Próxima Aula"
      ],
      "metadata": {
        "id": "h7m_6tpES5xC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exercícios"
      ],
      "metadata": {
        "id": "vCJSzsBOTNIw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Referências\n",
        "\n",
        "- Fukushima, K. (1980). Neocognitron: A self-organizing neural network model for a mechanism of pattern recognition unaffected by shift in position. Biological cybernetics, 36(4), 193-202.\n",
        "- LeCun, Y., Bottou, L., Bengio, Y., & Haffner, P. (1998). Gradient-based learning applied to document recognition. Proceedings of the IEEE, 86(11), 2278-2324.\n",
        "- LeNail, (2019). NN-SVG: Publication-Ready Neural Network Architecture Schematics. Journal of Open Source Software, 4(33), 747, https://doi.org/10.21105/joss.00747"
      ],
      "metadata": {
        "id": "fpwSyDT9TPKA"
      }
    }
  ]
}