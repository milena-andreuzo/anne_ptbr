{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP+FMEAKreovMZm681WObqP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vhrique/anne_ptbr/blob/main/04_RNN_Transformers.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "J7OlpqTkZJbq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Arquiteturas Especializadas em Processamento de Dados Sequenciais"
      ],
      "metadata": {
        "id": "0NR9C5yxjvkh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Redes Neurais Recorrentes\n",
        "\n",
        "As Redes Neurais Recorrentes (RNNs) são uma classe de redes projetadas especificamente para processar dados sequenciais, como séries temporais, texto ou áudio. Ao contrário das redes tradicionais, as RNNs têm conexões que permitem que a saída de uma unidade seja usada como entrada para a próxima, criando uma memória temporal que ajuda a capturar dependências entre os elementos da sequência. Isso as torna particularmente eficazes para tarefas como previsão de séries temporais, tradução automática e reconhecimento de fala.\n",
        "\n",
        "<center><img src=\"https://github.com/vhrique/anne_ptbr/blob/main/figures/RNN.png?raw=true\" width=500></center>"
      ],
      "metadata": {
        "id": "QA3IsL6YQNUY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### RNNs Clássicas e Backpropagation Throught Time\n",
        "\n",
        "As RNNs clássicas processam sequências de dados com base em uma memória interna que se atualiza a cada novo passo da sequência, permitindo que a rede armazene informações sobre entradas anteriores. Isso é possível porque cada neurônio recebe, além da entrada atual, o estado oculto da etapa anterior, o que permite que as redes RNN processem uma sequência de dados etapa por etapa.\n",
        "\n",
        "O treinamento dessas redes utiliza um algoritmo conhecido como Backpropagation Through Time (BPTT), que é uma extensão do tradicional backpropagation para dados sequenciais (Werbos, 1990). No BPTT, os erros são retropropagados não apenas através das camadas da rede, mas também ao longo do tempo, de uma etapa da sequência para a anterior. Isso permite que a RNN aprenda dependências temporais, ajustando os pesos para minimizar o erro em várias etapas.\n",
        "<center><img src=\"https://github.com/vhrique/anne_ptbr/blob/main/figures/rnn_unfold.png?raw=true\" width=600></center>\n",
        "\n",
        "No entanto, RNNs simples podem sofrer com problemas de gradiente desvanecente, dificultando o aprendizado de dependências de longo prazo. Para lidar com isso, variantes como LSTM (Long Short-Term Memory) e GRU (Gated Recurrent Unit) foram desenvolvidas, introduzindo mecanismos que controlam o fluxo de informações e preservam a memória por períodos mais longos, tornando-as mais eficazes em capturar padrões complexos em dados sequenciais."
      ],
      "metadata": {
        "id": "PdvBrbOOQQe0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### LSTM (1997)\n",
        "\n",
        "A LSTM (Long Short-Term Memory) é uma variante avançada das RNNs, projetada para lidar com o problema do gradiente desvanecente, que afeta as redes recorrentes clássicas quando tentam aprender dependências de longo prazo. Introduzida por Hochreiter e Schmidhuber em 1997, a LSTM utiliza um sistema de portas (entrada, esquecimento e saída) que controla o fluxo de informações em cada célula da rede. A porta de esquecimento decide quais informações devem ser descartadas da memória, enquanto a porta de entrada atualiza a memória com novas informações e a porta de saída seleciona o que será passado para a próxima etapa. Esse mecanismo permite que a LSTM preserve e manipule informações ao longo de grandes intervalos de tempo, tornando-a muito eficaz para tarefas que exigem capturar dependências complexas e de longo prazo, como tradução automática, reconhecimento de fala e previsão de séries temporais. A LSTM foi um avanço crucial no campo de redes recorrentes, permitindo um aprendizado mais eficiente e robusto em sequências longas.\n",
        "<center><img src=\"https://github.com/vhrique/anne_ptbr/blob/main/figures/lstm.png?raw=true\" width=500></center>"
      ],
      "metadata": {
        "id": "yu8g4hKfQV2C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### GRU (2014)\n",
        "\n",
        "A GRU (Gated Recurrent Unit) é uma variante das redes LSTM, proposta por Cho et al. em 2014, que simplifica o design das LSTMs, mantendo muitos de seus benefícios. Diferente da LSTM, a GRU combina as funcionalidades das portas de entrada e de esquecimento em uma única porta de atualização, e usa uma porta de reset para controlar a quantidade de informação que flui do estado anterior para o atual. Essa simplificação torna a GRU mais eficiente em termos de computação e memória, já que ela tem menos parâmetros do que a LSTM, sem sacrificar o desempenho em muitas tarefas. A GRU é particularmente eficaz para capturar dependências temporais de curto e longo prazo, tornando-a uma escolha popular em aplicações como tradução automática, modelagem de séries temporais e reconhecimento de fala. Devido à sua simplicidade e desempenho comparável ao da LSTM, a GRU é frequentemente usada quando há necessidade de redes mais leves e rápidas.\n",
        "\n",
        "<center><img src=\"https://github.com/vhrique/anne_ptbr/blob/main/figures/gru.png?raw=true\" width=400></center>"
      ],
      "metadata": {
        "id": "_LkQgCM1Qa0Y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Redes Bidirecionais\n",
        "\n",
        "As BiLSTM (Bidirectional Long Short-Term Memory) e BiGRU (Bidirectional Gated Recurrent Unit) são versões bidirecionais das arquiteturas LSTM e GRU, projetadas para capturar informações tanto do passado quanto do futuro em uma sequência de dados. Em vez de processar os dados apenas em uma direção (do início ao fim), essas redes utilizam duas camadas recorrentes: uma que processa a sequência na ordem tradicional e outra que processa na ordem inversa (Schuster et al., 1997). Essa abordagem permite que as redes bidirecionais captem dependências contextuais de ambas as direções, o que é especialmente útil em tarefas como tradução automática, onde o significado de uma palavra pode depender tanto do contexto anterior quanto do posterior, ou em reconhecimento de fala, onde a compreensão de um som pode ser influenciada por fonemas adjacentes. A BiLSTM é mais flexível, devido ao seu controle mais refinado de memória com as três portas, enquanto a BiGRU, por ser mais simples e eficiente, é preferida em cenários onde o desempenho computacional é uma prioridade. Ambas são amplamente usadas em processamento de linguagem natural e tarefas sequenciais complexas.\n",
        "\n",
        "<center><img src=\"https://github.com/vhrique/anne_ptbr/blob/main/figures/birnn.png?raw=true\" width=500></center>"
      ],
      "metadata": {
        "id": "ggSWJ1znjeTz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Desafios de Redes Neurais Recorrentes\n",
        "\n",
        "As RNNs apresentam desafios importantes, principalmente quando se trata de capturar dependências de longo prazo em dados sequenciais. Devido ao problema do gradiente desvanecente, as RNNs tendem a perder informações importantes conforme as dependências se tornam mais distantes ao longo da sequência, resultando em um aprendizado menos eficaz. Além disso, o processamento sequencial, onde cada etapa depende da anterior, torna o treinamento computacionalmente caro e difícil de paralelizar, limitando a eficiência da rede em grandes volumes de dados. Essas limitações prejudicaram o desempenho das RNNs em tarefas que requerem a análise de contextos mais longos e levaram à busca por soluções mais avançadas.\n",
        "\n"
      ],
      "metadata": {
        "id": "0NabXAVUkvvE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Mecanismos de Atenção (2014)\n",
        "\n",
        "Para superar as limitações das RNNs tradicionais, foi introduzido o mecanismo de atenção, que permite que a rede \"preste atenção\" em diferentes partes da sequência, independentemente da posição (Bahdanau et al., 2014). O mecanismo de atenção atua como um complemento ao processo recorrente, permitindo que a rede atribua pesos diferentes a diferentes elementos da entrada e capture informações relevantes, mesmo que estejam distantes na sequência. Isso melhora significativamente a capacidade das RNNs de lidar com dependências de longo alcance. Aplicações como a atenção em tradução automática demonstraram que esse mecanismo é eficaz para focar em palavras específicas de uma sentença ao traduzir, superando parte das limitações das RNNs puras.\n",
        "\n",
        "<center><img src=\"https://github.com/vhrique/anne_ptbr/blob/main/figures/bahdanau.JPG?raw=true\"></center>\n",
        "\n",
        "Na arquitetura de Bahdanu (2014) mostrada acima, vemos um modelo Sequência a Sequência (_Sequence to Sequence_ - Seq2seq), onde temos um codificador e um decodificador. No exemplo, o codificador é uma RNN bidirecional que extrai características $h_i$ para cada token $x_i$ na sequência de entrada $\\textbf{x}$ com comprimento $T$. O decodificador é uma RNN que calcula a saída $y_i$ de forma iterativa, passo-a-passo, utilizando o estado interno $s_i$, a saída anterior $y_{i-1}$ e um contexto $c_i$, enquanto o estado interno $s_i$ é uma função da saída anterior $y_{i-1}$, o estado anterior $s_{i-1}$ e o contexto $c_i$. Este contexto $c_i$ é uma média ponderada de todas as características $h_i$ calculadas pelo codificador, em função de pesos de atenção $a_i$. Cada um dos pesos de atenção $a_i$ é calculado como uma função das características $h_i$ e o estado interno do decodificador $s_{i-1}$. Neste caso, todas as funções são redes neurais aprendidas com os próprios dados."
      ],
      "metadata": {
        "id": "Y3bdrIbEQjcR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evolução em Processamento de Dados Sequenciais\n",
        "\n",
        "Com base no sucesso dos mecanismos de atenção, os Transformers, introduzidos em 2017 por Vasvani et al., levaram essa ideia ao próximo nível ao eliminar completamente a necessidade de recorrência. Os Transformers utilizam atenção auto-regressiva para processar toda a sequência de dados de uma vez, permitindo que a rede identifique dependências de curto e longo prazo de maneira eficiente, sem os problemas de gradientes desvanecentes. Isso também permite uma alta paralelização do processamento, acelerando consideravelmente o treinamento em grandes volumes de dados. Desde sua introdução, os Transformers se tornaram a arquitetura dominante em tarefas de processamento de linguagem natural e outras áreas, como visão computacional, devido à sua flexibilidade e eficiência."
      ],
      "metadata": {
        "id": "h4gH4FSHQhtZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Transformers (2017)\n",
        "\n",
        "A arquitetura do Transformer é baseada inteiramente em mecanismos de atenção, sem o uso de recorrência ou convolução. Ela consiste em dois blocos principais: um encoder e um decoder, ambos compostos de múltiplas camadas. Cada camada do encoder é formada por duas subcamadas principais: atenção auto-regressiva (self-attention), que permite que a rede atribua pesos a diferentes partes da sequência de entrada, e uma camada feed-forward que processa as características extraídas. O decoder segue uma estrutura similar, com a adição de uma subcamada de atenção cruzada que se conecta ao encoder, além de sua própria atenção auto-regressiva. Uma característica chave do Transformer é o uso de embeddings posicionais, que adicionam informações sobre a ordem dos elementos da sequência, algo que as RNNs capturam de forma nativa, mas que o Transformer precisa compensar. Essa estrutura permite que o Transformer processe sequências inteiras de forma paralelizada, tornando-o extremamente eficiente em tarefas como tradução automática, processamento de linguagem natural e até visão computacional.\n",
        "\n",
        "<center><img src=\"https://github.com/vhrique/anne_ptbr/blob/main/figures/transformer.png?raw=true\" width=300></center>\n",
        "\n",
        "### Self-Attention\n",
        "\n",
        "A self-attention (atenção auto-regressiva) é um mecanismo usado para permitir que modelos atribuam pesos diferentes a diferentes partes de uma sequência de entrada, dependendo da relevância contextual entre elas. Em vez de processar uma sequência de dados de forma sequencial, a self-attention permite que o modelo \"preste atenção\" em todas as posições da sequência simultaneamente, calculando a importância de cada elemento em relação aos outros. Isso é feito ao gerar três vetores para cada token da sequência: query (consulta), key (chave) e value (valor). O modelo calcula as similaridades entre as queries e keys, produzindo uma pontuação de atenção, que é usada para ponderar os valores correspondentes. Com o self-attention, o modelo pode identificar relações importantes em toda a sequência, de maneira eficiente e paralelizada.\n",
        "\n",
        "<center><img src=\"https://github.com/vhrique/anne_ptbr/blob/main/figures/self-attention.png?raw=true\" width=600></center>\n",
        "\n",
        "<center><img src=\"https://github.com/vhrique/anne_ptbr/blob/main/figures/attention_fix.jpg?raw=true\" width=700></center>\n",
        "\n",
        "### Layer Normalization\n",
        "\n",
        "Os Transformers lidam com sequências de comprimento variável, como frases ou parágrafos, onde cada token depende de sua posição na sequência. O BatchNorm, que normaliza as ativações com base em todo o lote, pode interferir nessas dependências temporais. Por outro lado, o LayerNorm normaliza cada amostra de forma independente, sem depender de outras amostras no lote, preservando assim as dependências temporais e contextuais dentro das sequências.\n",
        "\n",
        "<center><img src=\"https://github.com/vhrique/anne_ptbr/blob/main/figures/layernorm.jpg?raw=true\" width=300></center>\n",
        "\n",
        "A Layer Normalization (LayerNorm) foi introduzida em 2016, em um artigo intitulado \"Layer Normalization\" por Jimmy Lei Ba, Jamie Ryan Kiros e Geoffrey Hinton. A técnica foi desenvolvida para normalizar as ativações das camadas de redes neurais de forma independente em cada amostra, ao invés de calcular as estatísticas em lotes de dados como no Batch Normalization.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "i8GK6vH0p3JR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Avanços em Processamento de Linguagem Natural\n",
        "\n",
        "O Transformer revolucionou o processamento de linguagem natural (NLP) ao substituir arquiteturas sequenciais, como RNNs e LSTMs, por um mecanismo de atenção auto-regressiva que processa todo o contexto de uma sequência simultaneamente e de maneira paralela. Isso não apenas eliminou as limitações de capturar dependências de longo prazo, mas também permitiu uma paralelização eficiente do treinamento, acelerando significativamente o processamento em grandes volumes de dados. Modelos baseados no Transformer, como BERT e GPT, redefiniram o estado da arte em tarefas de NLP, como tradução, resposta a perguntas e geração de texto, graças à sua capacidade de capturar contextos complexos de maneira bidirecional ou autoregressiva.\n",
        "\n",
        "\n",
        "### BERT (2018)\n",
        "\n",
        "BERT (Bidirectional Encoder Representations from Transformers) é um modelo baseado na arquitetura Transformer, desenvolvido pela Google em 2018, que revolucionou o campo do processamento de linguagem natural (NLP). Ao contrário de modelos anteriores, que processavam texto em uma direção (da esquerda para a direita ou da direita para a esquerda), o BERT utiliza uma abordagem bidirecional para entender o contexto completo de uma palavra, considerando tanto as palavras anteriores quanto as subsequentes em uma sentença. BERT é treinado usando duas tarefas principais: máscara de palavras (Masked Language Modeling), onde o modelo tenta prever palavras escondidas em uma sentença, e previsão de sentenças adjacentes (Next Sentence Prediction), onde ele prevê se uma frase segue logicamente a outra. Essa abordagem permite ao BERT capturar nuances complexas de significado e relações contextuais profundas, o que o torna altamente eficaz em tarefas como classificação de texto, resposta a perguntas e tradução automática.\n",
        "\n",
        "### GPT (2018-2023)\n",
        "\n",
        "GPT (Generative Pre-trained Transformer) é uma arquitetura baseada no modelo Transformer desenvolvida pela OpenAI, com o foco em tarefas de geração de texto. Ao contrário de modelos bidirecionais como o BERT, o GPT é um modelo autorregressivo, processando a sequência de texto de forma unidirecional (da esquerda para a direita), prevendo a próxima palavra com base nas anteriores. GPT é pré-treinado em grandes volumes de dados para aprender a linguagem de maneira não supervisionada, sendo posteriormente ajustado para tarefas específicas. Com o lançamento de versões mais avançadas, como GPT-3 e GPT-4, o modelo se destacou pela sua capacidade de realizar uma ampla gama de tarefas, como tradução, resposta a perguntas, escrita criativa e geração de código, sem precisar de grandes quantidades de dados anotados. O uso de zero-shot e few-shot learning com GPT permitiu ao modelo generalizar para novas tarefas apenas com descrições mínimas ou alguns exemplos, transformando a maneira como abordamos o processamento de linguagem natural e outras aplicações de IA."
      ],
      "metadata": {
        "id": "k5Alyw8qQsy7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Avanços em Visão Computacional\n",
        "\n",
        "Os Transformers trouxeram avanços significativos para a visão computacional, especialmente com a introdução do Vision Transformer (ViT). O ViT adaptou o mecanismo de atenção auto-regressiva dos Transformers, originalmente desenvolvido para processamento de linguagem natural, para processar imagens de forma mais eficiente. Esses avanços permitiram aos Transformers superarem redes convolucionais tradicionais em diversas tarefas de visão computacional, como reconhecimento de objetos, segmentação semântica e detecção de anomalias, especialmente quando grandes volumes de dados estão disponíveis para o treinamento.\n",
        "\n",
        "### Vision Transformer (2020)\n",
        "\n",
        "O Vision Transformer (ViT) foi uma inovação no campo da visão computacional, ao adaptar o modelo de Transformers para processar imagens em vez de texto. Introduzido por Dosovitskiy et al. em 2020, o ViT substitui as convoluções tradicionais ao dividir uma imagem em pequenos patches e tratá-los como sequências de tokens, semelhantes às palavras em um texto. Utilizando o mecanismo de self-attention, o ViT é capaz de capturar relações globais e locais entre diferentes partes da imagem, permitindo uma compreensão mais rica do conteúdo visual. Essa abordagem mostrou-se altamente eficaz, especialmente em grandes conjuntos de dados, onde o ViT superou as redes convolucionais tradicionais em tarefas como classificação de imagens e segmentação. A simplicidade do design e a capacidade de paralelizar o treinamento são vantagens significativas, tornando o ViT uma arquitetura revolucionária no campo da visão computacional.\n",
        "\n",
        "<center><img src=\"https://github.com/vhrique/anne_ptbr/blob/main/figures/ViT.png?raw=true\" width=500></center>\n",
        "\n",
        "### Swin Transformer (2021)\n",
        "\n",
        "O Swin Transformer é uma evolução dos Transformers aplicados à visão computacional, projetado para melhorar a eficiência do Vision Transformer (ViT), especialmente em imagens de alta resolução. Introduzido por Liu et al. em 2021, o Swin Transformer utiliza uma abordagem hierárquica com janelas deslizantes (sliding windows), onde o mecanismo de self-attention é aplicado localmente dentro dessas janelas. Isso permite uma redução significativa no custo computacional, mantendo a capacidade de capturar relações entre diferentes partes da imagem. À medida que a rede avança, as janelas se expandem hierarquicamente, permitindo que o modelo capture tanto características locais quanto contextos globais de maneira eficiente. O Swin Transformer tem se destacado em diversas tarefas de visão, como segmentação de imagens, detecção de objetos e reconhecimento de cenas, oferecendo uma combinação poderosa de precisão e eficiência computacional.\n",
        "\n",
        "<center><img src=\"https://github.com/vhrique/anne_ptbr/blob/main/figures/swin-transformer.png?raw=true\" width=500></center>"
      ],
      "metadata": {
        "id": "WwubgE61Qv-I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Avanços em Escalabilidade\n",
        "\n",
        "Os Transformers, apesar de sua eficiência em capturar dependências globais, enfrentam desafios de escalabilidade, especialmente com dados de alta dimensão, como imagens e vídeos, devido ao alto custo computacional da auto-atenção, que cresce quadraticamente com o tamanho da entrada. Avanços como o Perceiver abordam esse problema ao utilizar uma abordagem de atenção latente, reduzindo a complexidade ao mapear entradas grandes para um espaço latente menor. Outra inovação é o Flash Attention, que otimiza o cálculo da auto-atenção ao reduzir o uso de memória e acelerar o processamento em GPUs. Esses avanços estão tornando os Transformers mais eficientes e escaláveis para uma gama maior de aplicações e volumes de dados.\n",
        "\n",
        "### Linformer\n",
        "\n",
        "O Linformer é uma variante dos Transformers que foi proposta para reduzir a complexidade computacional do cálculo de auto-atenção, que tradicionalmente cresce de forma quadrática com o número de tokens de entrada. A inovação do Linformer é a ideia de aproximar as matrizes de atenção de uma forma que elas tenham uma dimensão fixa, independentemente do comprimento da sequência de entrada. Isso é feito por meio de uma projeção linear das sequências, o que reduz o custo computacional da auto-atenção para complexidade linear. Essa abordagem torna o Linformer significativamente mais eficiente, especialmente em tarefas que envolvem sequências longas, como processamento de linguagem natural e visão computacional, sem comprometer a precisão dos modelos. O Linformer é particularmente útil para ambientes com restrições de recursos e para treinar modelos em grandes conjuntos de dados com alta eficiência.\n",
        "\n",
        "### Reformer\n",
        "\n",
        "O Reformer é uma arquitetura otimizada de Transformers, proposta para lidar com os desafios de escalabilidade e eficiência no processamento de grandes sequências. O Reformer introduz duas inovações principais para reduzir a complexidade computacional e o uso de memória. A primeira é o uso de Locality-Sensitive Hashing (LSH) na camada de auto-atenção, que aproxima a atenção ao comparar tokens similares de forma eficiente, reduzindo a complexidade da auto-atenção de quadrática para subquadrática. A segunda inovação é o uso de codificação reversível, o que elimina a necessidade de armazenar os estados intermediários de cada camada durante o treinamento, reduzindo significativamente o uso de memória. Essas melhorias tornam o Reformer capaz de processar sequências muito longas, como textos extensos ou vídeos, de forma mais escalável e eficiente, enquanto mantém a precisão dos Transformers tradicionais.\n",
        "\n",
        "### Big Bird\n",
        "\n",
        "O Big Bird é uma variante dos Transformers projetada para lidar com sequências extremamente longas, como documentos completos ou genomas, onde o cálculo tradicional de auto-atenção seria inviável devido ao alto custo computacional. Em vez de usar a atenção plena, o Big Bird introduz uma atenção esparsa que combina três tipos de atenção: local, global e aleatória. A atenção local captura relações próximas entre tokens, a atenção global foca em tokens importantes em posições fixas, e a atenção aleatória cria conexões entre tokens distantes de forma esparsa. Essa combinação reduz a complexidade da auto-atenção de quadrática para linear, permitindo o processamento eficiente de sequências muito maiores sem sacrificar o desempenho. O Big Bird se mostrou eficaz em várias tarefas de processamento de linguagem natural, como classificação de documentos, modelagem de linguagem, e até tarefas em bioinformática, demonstrando sua versatilidade e eficiência para grandes volumes de dados.\n",
        "\n",
        "<center><img src=\"https://github.com/vhrique/anne_ptbr/blob/main/figures/big-bird.png?raw=true\" width=500></center>\n",
        "\n",
        "### Perceiver e Perceiver IO (2021)\n",
        "\n",
        "O Perceiver foi desenvolvido para enfrentar as limitações de escalabilidade dos Transformers tradicionais, especialmente quando aplicados a entradas de alta dimensão, como vídeos ou nuvens de pontos 3D. Ao invés de processar todos os tokens de entrada diretamente, o Perceiver projeta os dados para um espaço latente de dimensão fixa, onde o mecanismo de atenção latente é aplicado, reduzindo drasticamente o custo computacional. Uma extensão, o Perceiver IO, vai além ao adaptar esse modelo para lidar com uma variedade de tipos de entradas e saídas, permitindo que o mesmo modelo processe dados como imagens, vídeos, texto e até sinais 3D, com diferentes formatos de saída. Com essa flexibilidade e eficiência, o Perceiver e o Perceiver IO estão tornando os Transformers mais adequados para aplicações multimodais e de grandes dimensões.\n",
        "\n",
        "<center><img src=\"https://github.com/vhrique/anne_ptbr/blob/main/figures/perceiver-io.png?raw=true\" width=500></center>\n",
        "\n",
        "### Flash Attention\n",
        "\n",
        "Flash Attention é uma técnica recente desenvolvida para otimizar o cálculo do mecanismo de auto-atenção em Transformers, reduzindo o uso de memória e acelerando o processamento. Tradicionalmente, o cálculo da auto-atenção tem um custo computacional quadrático em relação ao número de tokens de entrada, o que torna o processamento de sequências longas caro e ineficiente. O Flash Attention resolve esse problema ao realizar os cálculos de atenção de forma mais eficiente, armazenando somas parciais diretamente na memória e realizando as operações de forma fragmentada. Isso não só reduz o uso de memória como também melhora o desempenho em hardware como GPUs, permitindo que os Transformers processem sequências maiores com menos recursos computacionais. Essa técnica é especialmente útil em modelos grandes e para aplicações em larga escala, como processamento de linguagem natural e visão computacional."
      ],
      "metadata": {
        "id": "LlRXpy1pRhO7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Considerações Finais\n",
        "\n",
        "Na aula, abordamos três arquiteturas fundamentais de redes neurais: CNNs, que são amplamente utilizadas em visão computacional para extrair características espaciais de imagens; RNNs, projetadas para lidar com dados sequenciais, como séries temporais e texto, capturando dependências temporais; e Transformers, que revolucionaram o processamento de linguagem natural e, mais recentemente, a visão computacional, ao usar mecanismos de atenção auto-regressiva para capturar relações globais de forma eficiente e paralelizada. Cada uma dessas arquiteturas tem aplicações específicas e vantagens únicas, sendo marcos importantes no desenvolvimento da inteligência artificial.\n",
        "\n",
        "## RNN vs Transformer\n",
        "\n",
        "As RNNs e os Transformers são ambos usados para processar dados sequenciais, mas diferem fundamentalmente em seu funcionamento. As RNNs processam a sequência de dados de forma sequencial, etapa por etapa, o que limita a eficiência e dificulta a captura de dependências de longo prazo devido ao problema do gradiente desvanecente. Já os Transformers utilizam o mecanismo de self-attention, permitindo que o modelo capture dependências em qualquer posição da sequência de forma paralelizada e mais eficiente, superando as limitações das RNNs. Como resultado, os Transformers têm se tornado o padrão em muitas tarefas de processamento de linguagem natural e visão computacional, substituindo as RNNs em diversas aplicações.\n",
        "\n",
        "## CNN vs ViT\n",
        "\n",
        "As CNNs (Redes Neurais Convolucionais) e os Vision Transformers (ViT) são ambas arquiteturas utilizadas para visão computacional, mas diferem na forma como processam imagens. As CNNs utilizam convoluções locais, aplicando filtros para detectar padrões como bordas e texturas em pequenas regiões da imagem, com forte viés indutivo sobre a estrutura espacial. Já o ViT trata a imagem como uma sequência de patches (pequenos blocos), utilizando o mecanismo de self-attention para capturar relações globais e locais de forma mais flexível. As CNNs são mais eficientes em conjuntos de dados menores, mas o ViT se destaca em grandes volumes de dados, onde pode superar as CNNs em termos de desempenho, graças à sua capacidade de modelar dependências globais de maneira eficiente.\n",
        "\n",
        "## MLP vs Transformer\n",
        "\n",
        "As MLPs (Multilayer Perceptrons) e os Transformers são ambas redes neurais, mas têm diferenças fundamentais em como processam dados. O MLP é uma arquitetura mais simples, composta por camadas totalmente conectadas que tratam cada entrada de forma independente, sem considerar a estrutura dos dados. Isso limita sua capacidade de capturar relações complexas ou estruturais entre os elementos dos dados, como sequências temporais ou imagens. Em contraste, os Transformers utilizam o mecanismo de self-attention, permitindo que o modelo capture dependências globais entre diferentes partes de uma sequência, como palavras em um texto ou patches em uma imagem, de forma mais eficiente. Enquanto os MLPs são eficientes em tarefas simples e estruturadas, os Transformers se destacam em tarefas que exigem capturar relações contextuais complexas, como processamento de linguagem natural e visão computacional.\n",
        "\n",
        "## Próxima Aula\n",
        "\n",
        "Na próxima aula, trataremos sobre paradigmas avançados de redes neurais artificiais, como aprendizagem auto-supervisionada, contrastive learning e meta-learning."
      ],
      "metadata": {
        "id": "h7m_6tpES5xC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exercícios\n",
        "\n",
        "1. Verifique os exemplos da aula 4 para série temporal e processamento de linguagem natural\n",
        "2. Responda as seguintes perguntas:\n",
        "  1. Porque a LSTM foi mais eficiente que a MLP?\n",
        "  2. Qual a grande desvantagem de Transformers?\n",
        "3. Altere a LSTM por uma GRU no exemplo 4.a. Qual foi o resultado?"
      ],
      "metadata": {
        "id": "vCJSzsBOTNIw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Referências\n",
        "\n",
        "- Fukushima, K. (1980). Neocognitron: A self-organizing neural network model for a mechanism of pattern recognition unaffected by shift in position. Biological cybernetics, 36(4), 193-202.\n",
        "- LeCun, Y., Bottou, L., Bengio, Y., & Haffner, P. (1998). Gradient-based learning applied to document recognition. Proceedings of the IEEE, 86(11), 2278-2324.\n",
        "- LeNail, (2019). NN-SVG: Publication-Ready Neural Network Architecture Schematics. Journal of Open Source Software, 4(33), 747, https://doi.org/10.21105/joss.00747\n",
        "- Krizhevsky, A., Sutskever, I., & Hinton, G. E. (2012). Imagenet classification with deep convolutional neural networks. Advances in neural information processing systems, 25.\n",
        "- Nair, V., & Hinton, G. E. (2010). Rectified linear units improve restricted boltzmann machines. In Proceedings of the 27th international conference on machine learning (ICML-10) (pp. 807-814).\n",
        "- Zhang, C., Bengio, S., Hardt, M., Recht, B., & Vinyals, O. (2021). Understanding deep learning (still) requires rethinking generalization. Communications of the ACM, 64(3), 107-115.\n",
        "- Zhang, C., Bengio, S., Hardt, M., Recht, B., & Vinyals, O. (2021). Understanding deep learning (still) requires rethinking generalization. Communications of the ACM, 64(3), 107-115.\n",
        "- Simonyan, K., & Zisserman, A. (2014). Very deep convolutional networks for large-scale image recognition. arXiv preprint arXiv:1409.1556.\n",
        "- Szegedy, C., Liu, W., Jia, Y., Sermanet, P., Reed, S., Anguelov, D., ... & Rabinovich, A. (2015). Going deeper with convolutions. In Proceedings of the IEEE conference on computer vision and pattern recognition (pp. 1-9).\n",
        "- He, K., Zhang, X., Ren, S., & Sun, J. (2016). Deep residual learning for image recognition. In Proceedings of the IEEE conference on computer vision and pattern recognition (pp. 770-778).\n",
        "- Ioffe, S. (2015). Batch normalization: Accelerating deep network training by reducing internal covariate shift. arXiv preprint arXiv:1502.03167.\n",
        "- Werbos, P. J. (1990). Backpropagation through time: what it does and how to do it. Proceedings of the IEEE, 78(10), 1550-1560.\n",
        "- Hochreiter, S. (1997). Long Short-term Memory. Neural Computation MIT-Press.\n",
        "- Cho, K. (2014). On the Properties of Neural Machine Translation: Encoder-decoder Approaches. arXiv preprint arXiv:1409.1259.\n",
        "- Schuster, M., & Paliwal, K. K. (1997). Bidirectional recurrent neural networks. IEEE transactions on Signal Processing, 45(11), 2673-2681.\n",
        "- Bahdanau, D. (2014). Neural machine translation by jointly learning to align and translate. arXiv preprint arXiv:1409.0473.\n",
        "- Vaswani, A. (2017). Attention is all you need. Advances in Neural Information Processing Systems.\n",
        "- Ba, J. L. (2016). Layer normalization. arXiv preprint arXiv:1607.06450.\n",
        "- Devlin, J. (2018). Bert: Pre-training of deep bidirectional transformers for language understanding. arXiv preprint arXiv:1810.04805.\n",
        "- Radford, A. (2018). Improving language understanding by generative pre-training.\n",
        "- Radford, A., Wu, J., Child, R., Luan, D., Amodei, D., & Sutskever, I. (2019). Language models are unsupervised multitask learners. OpenAI blog, 1(8), 9.\n",
        "- Brown, T. B. (2020). Language models are few-shot learners. arXiv preprint arXiv:2005.14165.\n",
        "- Achiam, J., Adler, S., Agarwal, S., Ahmad, L., Akkaya, I., Aleman, F. L., ... & McGrew, B. (2023). Gpt-4 technical report. arXiv preprint arXiv:2303.08774.\n",
        "- Dosovitskiy, A. (2020). An image is worth 16x16 words: Transformers for image recognition at scale. arXiv preprint arXiv:2010.11929.\n",
        "- Liu, Z., Lin, Y., Cao, Y., Hu, H., Wei, Y., Zhang, Z., ... & Guo, B. (2021). Swin transformer: Hierarchical vision transformer using shifted windows. In Proceedings of the IEEE/CVF international conference on computer vision (pp. 10012-10022).\n",
        "- Wang, S., Li, B. Z., Khabsa, M., Fang, H., & Ma, H. (2020). Linformer: Self-attention with linear complexity. arXiv preprint arXiv:2006.04768.\n",
        "- Kitaev, N., Kaiser, Ł., & Levskaya, A. (2020). Reformer: The efficient transformer. arXiv preprint arXiv:2001.04451.\n",
        "- Zaheer, M., Guruganesh, G., Dubey, K. A., Ainslie, J., Alberti, C., Ontanon, S., ... & Ahmed, A. (2020). Big bird: Transformers for longer sequences. Advances in neural information processing systems, 33, 17283-17297.\n",
        "- Jaegle, A., Gimeno, F., Brock, A., Vinyals, O., Zisserman, A., & Carreira, J. (2021, July). Perceiver: General perception with iterative attention. In International conference on machine learning (pp. 4651-4664). PMLR.\n",
        "- Jaegle, A., Borgeaud, S., Alayrac, J. B., Doersch, C., Ionescu, C., Ding, D., ... & Carreira, J. (2021). Perceiver io: A general architecture for structured inputs & outputs. arXiv preprint arXiv:2107.14795.\n",
        "- Dao, T., Fu, D., Ermon, S., Rudra, A., & Ré, C. (2022). Flashattention: Fast and memory-efficient exact attention with io-awareness. Advances in Neural Information Processing Systems, 35, 16344-16359.\n",
        "\n"
      ],
      "metadata": {
        "id": "fpwSyDT9TPKA"
      }
    }
  ]
}