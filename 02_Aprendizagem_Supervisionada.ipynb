{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM/bK8PlElekZUo+mNkpiNh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vhrique/anne2024/blob/main/02_Aprendizagem_Supervisionada.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pacotes Utilizados nesta Aula"
      ],
      "metadata": {
        "id": "Cd3zeiof939j"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oEATqw6E9wuI"
      },
      "outputs": [],
      "source": [
        "import torch"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Paradigmas de Aprendizagem\n",
        "\n",
        "Os paradigmas de aprendizagem em redes neurais artificiais (RNAs) são baseados em diferentes maneiras de treinar um modelo e interagir com os dados.\n",
        "De forma geral, existem três paradigmas principais: aprendizagem supervisionada, aprendizagem não supervisionada e aprendizagem por reforço.\n",
        "Cada um desses paradigmas possui métodos distintos de treinar modelos, com base na disponibilidade e tipo de dados, bem como no objetivo final da tarefa.\n",
        "\n",
        "Na aprendizagem supervisionada, o modelo aprende a partir de dados rotulados, tentando prever uma saída correta com base em entradas específicas.\n",
        "\n",
        "<center><img src=\"https://github.com/vhrique/anne2024/blob/main/figures/supervised.jpg?raw=true\" width=\"500\"></center>\n",
        "\n",
        "Já na aprendizagem não supervisionada, os dados não possuem rótulos, e o modelo busca identificar padrões ou estruturas nos dados, como clusters ou associações.\n",
        "\n",
        "<center><img src=\"https://github.com/vhrique/anne2024/blob/main/figures/clustering.jpg?raw=true\" width=\"500\"></center>\n",
        "\n",
        "Por fim, na aprendizagem por reforço, o modelo aprende através da interação com um ambiente, recebendo recompensas ou penalidades com base nas ações tomadas, ajustando seu comportamento para maximizar a recompensa ao longo do tempo.\n",
        "\n",
        "<center><img src=\"https://github.com/vhrique/anne2024/blob/main/figures/reinforcement.jpg?raw=true\" width=\"300\"></center>"
      ],
      "metadata": {
        "id": "OWbVFRonHWQ9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Aprendizagem Supervisionada\n",
        "\n",
        "Entre os paradigmas de aprendizagem mais relevantes está a aprendizagem supervisionada, que será o foco desta aula.\n",
        "\n",
        "Na aprendizagem supervisionada, o modelo é treinado utilizando um conjunto de dados rotulados, ou seja, para cada entrada, há uma saída esperada conhecida.\n",
        "O objetivo do modelo é aprender uma função que mapeia as entradas para as saídas corretas, generalizando esse conhecimento para prever novas amostras.\n",
        "Esse paradigma é amplamente aplicado em tarefas de classificação e regressão."
      ],
      "metadata": {
        "id": "KFn3siWi-AZC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Problemas de Classificação\n",
        "\n",
        "Na classificação, o modelo aprende a categorizar entradas em uma ou mais classes.\n",
        "Um exemplo clássico é a classificação de imagens de dígitos escritos à mão, onde o modelo deve identificar corretamente o dígito (0 a 9) de uma imagem.\n",
        "O modelo aprende a identificar padrões que distinguem uma classe de outra.\n",
        "\n",
        "As três principais categorias de classificação são classificação binária, classificação multiclasse e classificação multilabel. Cada uma tem suas próprias características e desafios."
      ],
      "metadata": {
        "id": "1nd2T5Uh-Ixk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Classificação Binária\n",
        "\n",
        "Na classificação binária, o modelo tem que decidir entre duas classes possíveis.\n",
        "Por exemplo, um modelo pode classificar e-mails como \"spam\" ou \"não spam\". As saídas são representadas por um único valor, geralmente 0 ou 1, onde 0 pode significar \"classe negativa\" e 1 \"classe positiva\".\n",
        "A função de ativação mais comum usada para esse tipo de problema é a sigmoide, que gera uma probabilidade entre 0 e 1.\n",
        "A função de perda mais utilizada é a Binary Cross-Entropy (BCE)."
      ],
      "metadata": {
        "id": "2XE85yZNKFVj"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SrP9xb8baCBR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Classificação Multiclasse\n",
        "\n",
        "Na classificação multiclasse, o modelo precisa classificar as entradas em mais de duas classes mutuamente exclusivas.\n",
        "Um exemplo clássico é a classificação de imagens de dígitos escritos à mão, onde cada dígito (0 a 9) é uma classe diferente.\n",
        "Nesse caso, o modelo produz uma única saída que corresponde a uma das classes.\n",
        "A função de ativação comumente usada para multiclasse é a softmax, que normaliza as saídas para que elas somem 1, permitindo a interpretação dessas saídas como probabilidades.\n",
        "A função de perda mais comum é a Cross-Entropy (entropia cruzada)."
      ],
      "metadata": {
        "id": "DZpb0eelKHbO"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vMU8P59VaCb5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Classificação Multilabel\n",
        "\n",
        "Na classificação multilabel, cada entrada pode pertencer simultaneamente a várias classes, ou seja, as classes não são mutuamente exclusivas.\n",
        "Por exemplo, um sistema de recomendação de filmes pode classificar um filme tanto como \"comédia\" quanto \"drama\", ou uma imagem pode conter vários objetos diferentes, como \"gato\", \"carro\" e \"árvore\".\n",
        "Nesse caso, o modelo produz várias saídas, uma para cada possível classe, e cada saída é tratada como um problema de classificação binária (ou seja, uma classe pode estar presente ou não).\n",
        "Aqui, a sigmoide é usada em cada saída, com a função de perda Binary Cross-Entropy aplicada individualmente para cada classe."
      ],
      "metadata": {
        "id": "s9873peAKJ6m"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wWfzv8zdaC15"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Problemas de Regressão\n",
        "\n",
        "Na regressão, o objetivo é prever um valor contínuo.\n",
        "Por exemplo, em problemas de previsão de temperatura, o modelo aprende a mapear uma série de variáveis (como pressão e umidade) para prever a temperatura futura.\n",
        "Ao contrário da classificação, onde as saídas são discretas, a regressão lida com variáveis contínuas."
      ],
      "metadata": {
        "id": "woHzcEYR-QxQ"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GOqustV3aDlR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Algoritmos de Otimização\n",
        "\n",
        "Os algoritmos de otimização são fundamentais para o processo de aprendizagem de redes neurais, pois determinam como os pesos dos neurônios são ajustados para minimizar a função de perda durante o treinamento.\n",
        "O objetivo da otimização é encontrar os melhores parâmetros (pesos e vieses) que permitam à rede fazer previsões precisas em novos dados.\n",
        "\n",
        "A função de perda mede o quão longe as previsões do modelo estão dos valores reais, e o papel do algoritmo de otimização é minimizar essa função ajustando gradualmente os pesos.\n",
        "Isso é feito por meio do cálculo do gradiente, que indica a direção e a magnitude da mudança necessária nos pesos.\n",
        "\n",
        "Agora, vamos explorar alguns dos principais algoritmos de otimização e suas evoluções:"
      ],
      "metadata": {
        "id": "LaQKV-YU-SqI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Gradiente Descendente\n",
        "\n",
        "O gradiente descendente é o algoritmo de otimização mais simples e amplamente utilizado.\n",
        "Ele funciona ajustando os pesos na direção oposta ao gradiente da função de perda com relação a esses pesos.\n",
        "A ideia é que, ao seguir essa direção de forma iterativa, o algoritmo chegue ao mínimo da função de perda, onde o modelo realiza as previsões mais precisas.\n",
        "\n",
        "Existem três variações principais do gradiente descendente:\n",
        "\n",
        "- Batch Gradient Descent: Calcula o gradiente em todo o conjunto de dados de treinamento antes de atualizar os pesos. Esse método pode ser lento e ineficiente para grandes conjuntos de dados.\n",
        "- Stochastic Gradient Descent (SGD): Atualiza os pesos para cada exemplo de treino individual, tornando o processo mais rápido, mas introduzindo maior variação nas atualizações.\n",
        "- Mini-Batch Gradient Descent: Combina os dois anteriores, calculando o gradiente em pequenos lotes de dados, acelerando o treinamento e suavizando a variação das atualizações."
      ],
      "metadata": {
        "id": "pFU_GM8cHu32"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2DBgT7DMaFq4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Momentum\n",
        "\n",
        "O Momentum foi introduzido como uma melhoria ao gradiente descendente.\n",
        "Ele acelera o processo de convergência em direção ao mínimo, acumulando uma fração do gradiente anterior em cada atualização.\n",
        "Isso ajuda a suavizar o caminho em direção ao mínimo, evitando oscilações, especialmente em direções que têm gradientes mais ruidosos.\n",
        "\n",
        "A ideia é que, em vez de seguir estritamente a direção do gradiente atual, o modelo leva em conta o \"momento\" da direção em que está se movendo, como uma bola rolando por uma superfície irregular.\n",
        "Isso permite que o modelo alcance o mínimo mais rapidamente."
      ],
      "metadata": {
        "id": "UxUeC9FcICIS"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "96Mc02LQaF_t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### RMSProp\n",
        "\n",
        "O RMSProp é um método de otimização adaptativo que ajusta a taxa de aprendizado individualmente para cada parâmetro, com base na magnitude dos gradientes recentes.\n",
        "Ele mantém uma média móvel quadrada dos gradientes ao longo do tempo e, ao dividir o gradiente atual por essa média, corrige a taxa de aprendizado para cada parâmetro.\n",
        "Isso faz com que RMSProp se adapte melhor a problemas com gradientes que variam em escalas diferentes.\n",
        "\n",
        "Essa adaptação da taxa de aprendizado para cada peso torna o treinamento mais estável e eficaz, especialmente em problemas como redes neurais profundas, onde as atualizações dos pesos podem variar muito."
      ],
      "metadata": {
        "id": "z-1SJV1GIDqA"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iq3A3H5kaGZN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ADAM\n",
        "\n",
        "O ADAM combina o melhor de dois mundos: as ideias do Momentum e do RMSProp.\n",
        "Ele calcula uma média móvel dos gradientes (como o Momentum) e uma média móvel dos quadrados dos gradientes (como o RMSProp), ajustando a taxa de aprendizado de forma adaptativa para cada parâmetro.\n",
        "\n",
        "ADAM também inclui uma correção para viés nos primeiros passos, garantindo que as médias móveis comecem corretamente ajustadas.\n",
        "Esse algoritmo é um dos mais populares atualmente, pois oferece uma convergência mais rápida e estável em diversos tipos de problemas de redes neurais, sendo menos sensível à escolha da taxa de aprendizado inicial."
      ],
      "metadata": {
        "id": "qSTI7LBNJf6X"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Ji-mSJDDaGyL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Outros Algoritmos\n",
        "\n",
        "Além dos algoritmos clássicos que discutimos (Gradiente Descendente, Momentum, RMSProp e ADAM), existem outros algoritmos de otimização relevantes que, dependendo do problema e das características da rede neural, podem oferecer vantagens em termos de desempenho ou convergência.\n",
        "\n",
        "O AdaGrad é um dos primeiros algoritmos de otimização adaptativos, introduzido antes do RMSProp.\n",
        "Ele ajusta a taxa de aprendizado para cada parâmetro de forma individual, com base nas atualizações anteriores.\n",
        "Isso significa que parâmetros raramente atualizados têm uma taxa de aprendizado maior, enquanto aqueles que já foram ajustados várias vezes têm a taxa de aprendizado reduzida.\n",
        "Embora seja útil em problemas esparsos, como no processamento de linguagem natural, onde algumas features são raras, AdaGrad pode sofrer de um decaimento excessivo da taxa de aprendizado, o que leva a convergência mais lenta em muitos casos.\n",
        "\n",
        "O AdaDelta é uma variação do AdaGrad, projetada para corrigir o problema de decaimento da taxa de aprendizado.\n",
        "Em vez de acumular todas as atualizações anteriores, como o AdaGrad, o AdaDelta mantém uma janela deslizante de atualizações recentes, limitando o impacto de atualizações passadas muito distantes.\n",
        "Isso mantém a adaptabilidade da taxa de aprendizado sem que ela diminua drasticamente ao longo do tempo.\n",
        "Assim como o RMSProp, AdaDelta é muito utilizado em redes profundas e outros problemas complexos.\n",
        "\n",
        "O Nadam é uma combinação de ADAM com o conceito de Nesterov Momentum.\n",
        "A diferença em relação ao Momentum clássico é que, no Nesterov Momentum, o cálculo do gradiente é realizado com uma \"visão antecipada\" da direção para onde os pesos estão se movendo, o que pode acelerar o processo de convergência.\n",
        "O Nadam aplica essa ideia no contexto do ADAM, resultando em um algoritmo que pode ser ligeiramente mais eficiente e estável do que o ADAM em certos cenários.\n",
        "\n",
        "O AMSGrad é uma modificação do ADAM que tenta resolver um problema de convergência observada no ADAM original, especialmente em situações onde a função de perda não é convexa.\n",
        "No ADAM, os parâmetros de aprendizado podem não convergir para o ótimo global em algumas situações.\n",
        "O AMSGrad corrige isso, garantindo que as médias móveis dos gradientes só decaiam, o que melhora a convergência em alguns problemas."
      ],
      "metadata": {
        "id": "TqWpKy9EPVb7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "uB6GULmZHnrp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Funções de Perda\n",
        "\n",
        "As funções de perda (ou funções de custo) são componentes centrais no treinamento de redes neurais, pois medem o quão bem o modelo está performando.\n",
        "Elas comparam as predições feitas pela rede com os valores reais e retornam um valor numérico que indica o erro da previsão.\n",
        "O objetivo do treinamento é minimizar essa função de perda ajustando os pesos da rede, com a ajuda de algoritmos de otimização, para que o erro se torne o menor possível.\n",
        "\n",
        "Essencialmente, a função de perda informa à rede neural como melhorar suas predições ao longo do processo de aprendizado.\n",
        "Dependendo do tipo de problema (classificação, regressão, multiclasse, etc.), diferentes funções de perda são utilizadas."
      ],
      "metadata": {
        "id": "oouf0OSw-XdU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Binary Cross-Entropy\n",
        "\n",
        "A Binary Cross-Entropy (BCE) é comumente usada em problemas de classificação binária, onde o objetivo é prever se uma amostra pertence a uma de duas classes.\n",
        "Essa função mede a diferença entre a probabilidade prevista e o valor real, penalizando fortemente predições erradas. A fórmula é:\n",
        "\n",
        "$$\n",
        "\\text{BCE} = - \\frac{1}{N}\\sum_{i=1}^{N}\\left[y_i.log(\\hat{y}_i) + (1 - y_i).log(1-\\hat{y}_i)\\right]\n",
        "$$\n",
        "\n",
        "Aqui, $y_i$ é o valor real (0 ou 1) e $\\hat{y}_i$ é a probabilidade prevista.\n",
        "O objetivo é minimizar essa diferença, fazendo com que a probabilidade prevista se aproxime do valor real.\n",
        "\n",
        "- Vantagem: Funciona muito bem com problemas binários, lidando com probabilidades.\n",
        "- Desvantagem: Pode ser mais sensível a problemas de balanço de classes."
      ],
      "metadata": {
        "id": "l6nKr-_dzLre"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "#### Multilabel Binary Cross-Entropy\n",
        "\n",
        "Em problemas de classificação multilabel, onde uma entrada pode pertencer a mais de uma classe, a Multilabel Binary Cross-Entropy é utilizada.\n",
        "É basicamente a BCE aplicada a cada rótulo individualmente.\n",
        "A fórmula é semelhante à da BCE, mas ajustada para várias saídas simultâneas.\n",
        "\n",
        "- Vantagem: Adequada para problemas onde uma entrada pertence a múltiplas classes.\n",
        "- Desvantagem: Pode se tornar ineficiente com um grande número de classes."
      ],
      "metadata": {
        "id": "D9syOiFgJosh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Categorical Cross-Entropy\n",
        "\n",
        "A Entropia Cruzada Categórica é usada em problemas de classificação multiclasse, onde o objetivo é prever uma entre várias classes mutuamente exclusivas.\n",
        "A fórmula é:\n",
        "\n",
        "$$\n",
        "\\text{CCE} = - \\frac{1}{N}\\sum_{i=1}^{N}\\sum_{j=1}^{C}y_{ij}.log(\\hat{y}_{ij})\n",
        "$$\n",
        "\n",
        "Aqui, $C$ é o número de classes, $y_{ij}$ é o valor real (geralmente um vetor one-hot) e $\\hat{y}_{ij}$ é a probabilidade prevista para a classe $j$.\n",
        "A _softmax_ é usada como função de ativação na saída, convertendo as predições em probabilidades.\n",
        "\n",
        "- Vantagem: Adequada para problemas com várias classes exclusivas.\n",
        "- Desvantagem: Não lida bem com situações em que uma instância pode pertencer a múltiplas classes."
      ],
      "metadata": {
        "id": "sz7NEBfzTAkA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Cross-Entropy como Função de Perda em Redes Neurais\n",
        "\n",
        "A entropia cruzada (cross-entropy) tem suas origens na teoria da informação, desenvolvida por Claude Shannon na década de 1940.\n",
        "A ideia central da teoria da informação é quantificar a quantidade de informação ou incerteza presente em um conjunto de dados, e a entropia é uma medida dessa incerteza.\n",
        "A entropia de Shannon mede o grau de imprevisibilidade de um sistema de eventos, sendo usada para descrever a incerteza associada a uma distribuição de probabilidades.\n",
        "\n",
        "No contexto de redes neurais, a entropia cruzada é uma medida da divergência entre duas distribuições de probabilidade: a distribuição verdadeira dos rótulos (a saída correta) e a distribuição prevista pelo modelo.\n",
        "A fórmula original da entropia cruzada é baseada na divergência de Kullback-Leibler (KL Divergence), que mede a diferença entre duas distribuições de probabilidade $P$ e $Q$.\n",
        "No caso de uma rede neural, $P$ é a distribuição verdadeira dos rótulos (normalmente representada por um vetor one-hot) e $Q$ é a distribuição de probabilidade prevista pelo modelo.\n",
        "\n",
        "A fórmula da entropia cruzada é dada por:\n",
        "\n",
        "$$\n",
        "H(P,Q) = - \\sum_{i=1}^{C}P(i)log(Q(i))\n",
        "$$\n",
        "\n",
        "Onde:\n",
        "\n",
        "- $P(i)$ é a probabilidade verdadeira para a classe $i$ (em problemas de classificação, geralmente 0 ou 1).\n",
        "- $Q(i)$ é a probabilidade prevista pelo modelo para a classe $i$.\n",
        "\n",
        "A entropia cruzada mede o quão bem o modelo está capturando a distribuição verdadeira dos rótulos.\n",
        "Quando $P(i)$ é 1 (ou seja, a classe $𝑖$ é a correta), a entropia cruzada penaliza o modelo se a probabilidade $𝑄(i)$ não estiver próxima de 1."
      ],
      "metadata": {
        "id": "rjPy1L8UVhtJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Margin (Hinge)\n",
        "\n",
        "O Hinge Loss é usado com máquinas de vetores de suporte (SVMs), mas também pode ser aplicado em redes neurais para problemas de classificação binária.\n",
        "Ele força o modelo a maximizar a margem entre as classes, penalizando erros de classificação de forma mais agressiva.\n",
        "\n",
        "A fórmula para um problema binário é:\n",
        "\n",
        "$$\n",
        "L = \\sum_{i=1}^{N}\\text{max}(0,1-y_i.\\hat{y}_i)\n",
        "$$\n",
        "\n",
        "Aqui, $y_i$ são os rótulos reais (+1 ou -1), $\\hat{y}_{i}$ e são as predições do modelo.\n",
        "\n",
        "- Vantagem: Eficaz em maximizar a separação entre as classes.\n",
        "- Desvantagem: Principalmente usado em SVMs e menos comum em redes neurais."
      ],
      "metadata": {
        "id": "UNjXoqpPJz0V"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Mean Squared Error\n",
        "\n",
        "O MSE é amplamente usado em problemas de regressão, onde o objetivo é prever valores contínuos.\n",
        "Ele mede a diferença média entre as predições do modelo e os valores reais, elevando ao quadrado essas diferenças para garantir que erros positivos e negativos não se cancelem.\n",
        "A fórmula é:\n",
        "\n",
        "$$\n",
        "\\text{MSE} = \\frac{1}{N}\\sum_{i=1}^N(y_i - \\hat{y}_i)^2\n",
        "$$\n",
        "\n",
        "onde $y_i$ é o valor real e $\\hat{y}_i$ é a predição do modelo.\n",
        "O quadrado das diferenças garante que erros grandes tenham um impacto maior no valor final.\n",
        "\n",
        "- Vantagem: Simples de calcular e amplifica grandes erros.\n",
        "- Desvantagem: Sensível a outliers, já que erros grandes têm um impacto desproporcional."
      ],
      "metadata": {
        "id": "cVV4DE8uJwwx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Mean Absolute Error\n",
        "\n",
        "O MAE é outra função de perda usada para problemas de regressão, mas, ao contrário do MSE, mede a diferença absoluta média entre os valores previstos e os valores reais.\n",
        "Sua fórmula é:\n",
        "\n",
        "$$\n",
        "\\text{MSE} = \\frac{1}{N}\\sum_{i=1}^N \\left|y_i - \\hat{y}_i \\right|\n",
        "$$\n",
        "\n",
        "- Vantagem: Mais robusto a outliers do que o MSE.\n",
        "- Desvantagem: Não diferencia grandes e pequenos erros da mesma forma que o MSE."
      ],
      "metadata": {
        "id": "3rY99ezyRNXR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Huber Loss\n",
        "\n",
        "A Huber Loss é uma função de perda que combina as vantagens do Erro Quadrático Médio (MSE) e do Erro Absoluto Médio (MAE), oferecendo uma abordagem robusta para problemas de regressão, especialmente na presença de outliers.\n",
        "Ela foi projetada para tratar grandes erros de forma mais eficiente do que o MSE, que é altamente sensível a outliers, enquanto mantém a simplicidade do MAE em regiões de pequenos erros.\n",
        "A fórmula da Huber Loss é definida de forma diferente para erros pequenos e grandes:\n",
        "\n",
        "$$\n",
        "L_{\\delta}(y_i, \\hat{y}_i) =\n",
        "\\begin{cases}\n",
        "\\frac{1}{2}(y_i - \\hat{y}_i)^2 & \\text{se } |y_i - \\hat{y}_i| \\leq \\delta \\\\\n",
        "\\delta \\cdot (|y_i - \\hat{y}_i| - \\frac{1}{2} \\delta) & \\text{se } |y_i - \\hat{y}_i| > \\delta\n",
        "\\end{cases}\n",
        "$$\n",
        "\n",
        "onde $y_i$ é o valor real, $\\hat{y}_i$ é a previsão do modelo e $\\delta$ é um parâmetro que define o limite entre erros pequenos e grandes.\n",
        "\n",
        "A Huber Loss funciona de forma suave em relação a pequenos erros, como o MSE, mas trata erros grandes de maneira mais robusta, como o MAE.\n",
        "Isso faz com que seja uma função intermediária que lida bem tanto com ruídos pequenos quanto com outliers, sendo especialmente útil em problemas de regressão.\n",
        "\n",
        "Vantagens:\n",
        "\n",
        "- Robustez a outliers: Quando há grandes erros ou outliers, a Huber Loss não amplifica esses erros tanto quanto o MSE, evitando que um pequeno número de outliers distorça significativamente o modelo.\n",
        "- Suavidade em pequenos erros: Para erros pequenos, a Huber Loss se comporta como o MSE, permitindo que a função de perda seja diferenciável e suave, o que facilita a otimização.\n",
        "\n",
        "Desvantagens:\n",
        "\n",
        "- Escolha de $\\delta$: O valor de\n",
        "$\\delta$ deve ser escolhido cuidadosamente, pois um valor mal ajustado pode levar a um comportamento inadequado da função de perda. Sefor muito pequeno, o modelo se comportará quase como o MAE, e se for muito grande, se aproximará do MSE, perdendo as vantagens da robustez\n",
        "\n",
        "A Huber Loss é amplamente utilizada em problemas de regressão onde há a presença de outliers nos dados, pois oferece um equilíbrio entre ser suave para erros pequenos e robusta para grandes erros. Além disso, é preferida em aplicações de machine learning onde o MSE tende a ser excessivamente influenciado por grandes outliers."
      ],
      "metadata": {
        "id": "Spe-X0XiKSOW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Outras Funções de Perda\n",
        "\n",
        "A KL Divergence é utilizada para medir a diferença entre duas distribuições de probabilidade, sendo particularmente útil em modelos probabilísticos, como variational autoencoders (VAEs).\n",
        "Ela não é propriamente uma função de perda no sentido tradicional, mas é amplamente usada para regularizar a distribuição de saída de um modelo para que seja similar a uma distribuição-alvo.\n",
        "\n",
        "A Cosine Similarity Loss mede o ângulo entre dois vetores, sendo usada para comparar a similaridade entre vetores em vez de medir a diferença absoluta.\n",
        "Isso é especialmente útil em problemas de aprendizado de representações, como em redes neurais siamesas e embedding learning.\n",
        "\n",
        "A Focal Loss foi introduzida para tratar o problema de desbalanceamento de classes, em que algumas classes são muito mais representadas que outras.\n",
        "Ela é uma modificação da entropia cruzada que coloca mais peso nas amostras difíceis (ou seja, aquelas que são classificadas de forma incorreta).\n",
        "\n",
        "Também chamada de Huber Loss, mas com uma implementação ligeiramente diferente, a Smooth L1 Loss é amplamente utilizada em redes neurais para detecção de objetos. Ela é mais robusta a outliers do que a MSE e mais estável do que o MAE.\n",
        "\n",
        "A Dice Loss é uma função de perda comumente usada em problemas de segmentação de imagens, especialmente em áreas médicas, onde é necessário calcular a sobreposição entre a área predita e a área verdadeira.\n",
        "É derivada do coeficiente de Dice, que mede a similaridade entre dois conjuntos.\n",
        "\n",
        "A Triplet Loss é usada para aprendizado de embeddings e aprendizado métrico, particularmente em redes siamesas.\n",
        "A função de perda incentiva a rede a reduzir a distância entre embeddings de amostras semelhantes (o ancor e o positivo) e aumentar a distância entre o ancor e amostras dissimilares (o negativo).\n",
        "\n",
        "A Wing Loss é uma função de perda desenhada especificamente para problemas de detecção de landmarks faciais, onde pequenos erros precisam ser suavemente penalizados, mas grandes erros devem ser penalizados de forma mais forte."
      ],
      "metadata": {
        "id": "ZwbBuiBwYw1O"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Aprendizagem = Representação + Otimização + Avaliação\n",
        "\n",
        "Conforme indicado por Pedro Domingos (2012), três componentes aparecem em todos os paradigmas de aprendizagem: representação, otimização e avaliação.\n",
        "Esses três componentes são fundamentais para qualquer paradigma de aprendizagem, desde as tarefas supervisionadas mais simples até as mais complexas formas de aprendizado, como o _self-supervised learning_.\n",
        "A interação entre esses componentes define o sucesso e a eficácia de um modelo ao generalizar para novos dados e resolver problemas reais.\n",
        "\n",
        "<center><img src=\"https://raw.githubusercontent.com/vhrique/anne2024/8eb24ed5fc4d5ffd55d1664b512417ad8a2d71a0/figures/mapa_mental_supervised_learning_reduced.drawio.svg\" width=\"600\"></center>\n",
        "\n",
        "## Representação\n",
        "\n",
        "A representação refere-se a como os dados e o conhecimento são modelados internamente pelo modelo. Ela define como as características dos dados serão manipuladas para que o modelo possa aprender padrões úteis, e sua escolha tem um impacto significativo no desempenho de um modelo.\n",
        "\n",
        "## Otimização\n",
        "\n",
        "O processo de otimização envolve a maneira como o modelo ajusta seus parâmetros internos para minimizar uma função de perda, que mede o quão longe as previsões estão das saídas desejadas. Em redes neurais, esse processo é realizado por algoritmos como o gradiente descendente, que ajusta os pesos das conexões neurais para minimizar a diferença entre a predição do modelo e o rótulo correto, através de técnicas como o backpropagation. Em suma, a otimização busca garantir que o modelo aprenda da melhor maneira possível com os dados disponíveis, ajustando-se para capturar os padrões mais relevantes e reduzir o erro nas predições.\n",
        "\n",
        "## Avaliação\n",
        "\n",
        "Por fim, a avaliação mede o quão bem o modelo aprendeu a tarefa. As métricas de avaliação variam conforme a tarefa e o tipo de aprendizado. Na aprendizagem supervisionada, por exemplo, para classificação, utilizamos métricas como acurácia ou F1-score, enquanto, em regressão, utilizamos erro quadrático médio (MSE) ou erro absoluto médio (MAE). Ao treinar redes neurais artificiais, utilizamos funções de perda para guiar o processo de aprendizagem por meio de otimização. Otimização e avaliação, portanto, são componentes complementares e essenciais para garantir que o modelo de aprendizado de máquina aprenda de forma eficiente e seja capaz de realizar boas previsões em novos dados.\n",
        "\n",
        "## Considerações sobre Representação e Viés Indutivo\n",
        "\n",
        "Diferentes algoritmos de aprendizado de máquina utilizam diferentes tipos de representação. Por exemplo, o K-Nearest Neighbors (KNN) representa os dados como pontos em um espaço métrico, assumindo que amostras próximas têm comportamentos similares, o que reflete um viés indutivo de proximidade espacial. Já em árvores de decisão, a representação dos dados é estruturada hierarquicamente, onde divisões sucessivas criam nós e folhas que categorizam as amostras, impondo um viés de segmentação binária nos dados.\n",
        "\n",
        "Nas redes neurais, os dados são representados de forma abstrata através de camadas de neurônios, onde cada camada transforma os dados em representações progressivamente mais complexas e abstratas, refletindo um viés indutivo de que os padrões nos dados podem ser aprendidos através de composições hierárquicas de funções não-lineares. Em uma rede neural profunda, por exemplo, camadas sucessivas de neurônios aprendem representações progressivamente mais complexas dos dados. No início, as camadas podem detectar bordas ou formas simples em uma imagem, enquanto camadas mais profundas podem aprender a identificar objetos ou partes mais complexas."
      ],
      "metadata": {
        "id": "5_xJdaLqHkV1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Referências\n",
        "\n",
        "- Domingos, P. (2012). A few useful things to know about machine learning. Communications of the ACM, 55(10), 78-87.\n",
        "- Shannon, C. E. (1948). A mathematical theory of communication. The Bell system technical journal, 27(3), 379-423."
      ],
      "metadata": {
        "id": "yg-Auww0LByt"
      }
    }
  ]
}