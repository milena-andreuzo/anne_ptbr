{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPzfsj1CLFkv2MIWkjNRJkk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vhrique/anne_ptbr/blob/development/04_Arquiteturas_Especializadas.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim"
      ],
      "metadata": {
        "id": "8PE0x_z83EVN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Introdução à Arquiteturas Especializadas\n",
        "\n",
        "As arquiteturas clássicas de redes neurais, como as redes densas (MLPs), convolucionais (CNNs) e recorrentes (RNNs), são amplamente usadas para tarefas de classificação e regressão, aproveitando sua estrutura para extrair padrões dos dados e realizar previsões. Essas redes, em geral, aprendem a mapear entradas para saídas rotuladas e são versáteis em diferentes domínios.\n",
        "\n",
        "No entanto, há arquiteturas especializadas que atendem a demandas mais específicas. Autoencoders, por exemplo, são redes projetadas para compressão de dados e extração de características latentes, enquanto GANs (Redes Generativas Adversárias) são usadas para a geração de dados sintéticos realistas. Em tarefas de visão computacional, arquiteturas voltadas para detecção de objetos e segmentação aprendem a identificar e localizar múltiplas classes em uma imagem, demonstrando a evolução do campo para resolver problemas além da classificação tradicional.\n",
        "\n",
        "Nesta aula, falaremos mais sobre estes tipos de arquiteturas e como isto muda em relação à representação, avaliação e otimização de modelos."
      ],
      "metadata": {
        "id": "-9Op2dJky8NF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Autoencoders\n",
        "\n",
        "Os autoencoders são um tipo de rede neural projetada para aprender uma representação compacta dos dados, também conhecida como codificação latente, de forma não supervisionada. Eles são compostos por duas partes principais: o codificador, que reduz a dimensionalidade dos dados de entrada ao projetá-los em um espaço latente de menor dimensão, e o decodificador, que tenta reconstruir os dados originais a partir dessa representação comprimida. A principal aplicação dos autoencoders está em tarefas como redução de dimensionalidade, remoção de ruído e geração de novas amostras.\n",
        "\n",
        "A avaliação de autoencoders geralmente é feita comparando a similaridade entre os dados de entrada e sua reconstrução gerada pelo decodificador, utilizando métricas como erro quadrático médio (MSE) ou entropia cruzada, dependendo do tipo de dados. O objetivo é minimizar essa diferença, o que indica que o autoencoder aprendeu uma boa representação latente. A otimização dos autoencoders é realizada através de técnicas padrão de redes neurais, como a _backpropagation_ e o uso de algoritmos de otimização, como o gradiente descendente e suas variantes."
      ],
      "metadata": {
        "id": "mf4q3gPwUZLd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Autoencoder(nn.Module):\n",
        "    def __init__(self, input_size):\n",
        "        super(Autoencoder, self).__init__()\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Linear(input_size, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(256, 64),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.Linear(64, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(256, input_size)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.encoder(x)\n",
        "        x = self.decoder(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "UaCEa8-Z3GQC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Autoencoder(input_size=1_000)\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "criterion = nn.MSELoss()"
      ],
      "metadata": {
        "id": "FK1lUUjS3Y-F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Variational Autoencoders\n",
        "\n",
        "Os autoencoders variacionais (VAEs) são uma extensão dos autoencoders tradicionais que introduzem uma abordagem probabilística para a geração de dados. Em vez de codificar os dados diretamente em um espaço latente fixo, os VAEs aprendem distribuições probabilísticas que representam as características latentes dos dados, com a rede aprendendo os parâmetros de média e variância dessas distribuições. Essa estrutura permite que o modelo gere novas amostras ao amostrar dessas distribuições latentes, o que torna os VAEs ideais para tarefas como síntese de dados, geração de imagens e aprendizado de características latentes com maior capacidade de generalização.\n",
        "\n",
        "Em termos de avaliação e otimização, além da reconstrução dos dados, o VAE incorpora na função de perda um termo de regularização chamado divergência Kullback-Leibler (KL), que mede o quão próxima a distribuição latente aprendida está de uma distribuição normal padrão. A otimização, então, busca equilibrar dois objetivos: minimizar a perda de reconstrução, para garantir que a entrada seja bem reconstruída, e minimizar a divergência KL, para manter a estrutura latente bem regularizada. Esse processo permite que o VAE não apenas reconstrua os dados, mas também gere novas amostras de maneira mais controlada e com maior capacidade de generalização."
      ],
      "metadata": {
        "id": "EjjllYLMzpw9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class VAE(nn.Module):\n",
        "    def __init__(self, input_size):\n",
        "        super(VAE, self).__init__()\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Linear(input_size, 400),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "        self.mu_layer = nn.Linear(400, 20)\n",
        "        self.logvar_layer = nn.Linear(400, 20)  # Log variância\n",
        "\n",
        "        # Decoder\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.Linear(20, 400),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(400, input_size),\n",
        "        )\n",
        "\n",
        "    def reparameterize(self, mu, logvar):\n",
        "        std = torch.exp(0.5 * logvar)\n",
        "        eps = torch.randn_like(std)\n",
        "        return mu + eps * std\n",
        "\n",
        "    def forward(self, x):\n",
        "        encoded = self.encoder(x)\n",
        "        mu = self.mu_layer(encoded)\n",
        "        logvar = self.logvar_layer(encoded)\n",
        "        z = self.reparameterize(mu, logvar)\n",
        "        decoded = self.decoder(z)\n",
        "        return decoded, mu, logvar\n",
        "\n",
        "def loss_function(recon_x, x, mu, logvar):\n",
        "    BCE = nn.functional.binary_cross_entropy(recon_x, x, reduction='sum')\n",
        "    KLD = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp()) # KL Diverg.\n",
        "    return BCE + KLD"
      ],
      "metadata": {
        "id": "Mo0JnW_P3g16"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vae = VAE(input_size=1_000)\n",
        "optimizer = optim.Adam(vae.parameters(), lr=0.001)"
      ],
      "metadata": {
        "id": "D-PklUzb39X8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Visão Computacional"
      ],
      "metadata": {
        "id": "e0v68ocrabjX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Detecção de Objetos"
      ],
      "metadata": {
        "id": "hgTI6j4mao_w"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### R-CNN (2014)"
      ],
      "metadata": {
        "id": "WxR7386yawlC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Fast R-CNN (2015)"
      ],
      "metadata": {
        "id": "pDa7Azfraz7D"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Faster R-CNN (2015)"
      ],
      "metadata": {
        "id": "0xF4d_0na_f8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### YOLO (2015 - ...)"
      ],
      "metadata": {
        "id": "vux8mz_VbFz8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### RetinaNet (2017)"
      ],
      "metadata": {
        "id": "zcrFS4AtbO02"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### DETR (2020)"
      ],
      "metadata": {
        "id": "ruIbBB82be8I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Segmentação de Imagens"
      ],
      "metadata": {
        "id": "JLV9_fVZbR5I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### FCN (2015)"
      ],
      "metadata": {
        "id": "GEvCzX7IbUmk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### U-Net (2015)"
      ],
      "metadata": {
        "id": "ECcpT9wDb1gM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### DeepLab (2015 - ...)"
      ],
      "metadata": {
        "id": "hP6qvI-ScAZm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Mask R-CNN (2017)"
      ],
      "metadata": {
        "id": "WtzGRdLNcDjK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### SAM (2023)"
      ],
      "metadata": {
        "id": "BMELm-PGcHLv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Geração e Transformação de Imagens"
      ],
      "metadata": {
        "id": "COL0-bZpce9j"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Generative Adversarial Networks"
      ],
      "metadata": {
        "id": "yXa1i3aSUe99"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### StyleGAN"
      ],
      "metadata": {
        "id": "UXylQcHKcwrN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### CycleGAN"
      ],
      "metadata": {
        "id": "ZrJ_iD_vcy7A"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### PixelRNN"
      ],
      "metadata": {
        "id": "eGR3Ga7ndGxO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Processamento de Linguagem Natural"
      ],
      "metadata": {
        "id": "PqC8ej35dT5g"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Seq2Seq"
      ],
      "metadata": {
        "id": "6VQsm70EdWP6"
      }
    }
  ]
}